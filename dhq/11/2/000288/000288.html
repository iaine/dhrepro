<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><title>DHQ: Digital Humanities Quarterly: OCR of historical printings with an application to building
                    diachronic corpora: A case study using the RIDGES herbal corpus</title><link rel="stylesheet" type="text/css" href="/dhq/common/css/dhq.css"/><link rel="stylesheet" type="text/css" media="screen" href="/dhq/common/css/dhq_screen.css"/><link rel="stylesheet" type="text/css" media="print" href="/dhq/common/css/dhq_print.css"/><link rel="alternate" type="application/atom+xml" href="/dhq/feed/news.xml"/><link rel="shortcut icon" href="/dhq/common/images/favicon.ico"/><script type="text/javascript" src="/dhq/common/js/javascriptLibrary.js">
                &lt;!-- Javascript functions --&gt;
            </script><script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-15812721-1']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
s.parentNode.insertBefore(ga, s);
 })();

        </script></head><body><div id="top"><div id="backgroundpic"><script type="text/javascript" src="/dhq/common/js/pics.js"><!--displays banner image--></script></div><div id="banner"><div id="dhqlogo"><img src="/dhq/common/images/dhqlogo.png" alt="DHQ Logo"/></div><div id="longdhqlogo"><img src="/dhq/common/images/dhqlogolonger.png" alt="Digital Humanities Quarterly Logo"/></div></div><div id="topNavigation"><div id="topnavlinks"><span><a href="/dhq/" class="topnav">home</a></span><span><a href="/dhq/submissions/index.html" class="topnav">submissions</a></span><span><a href="/dhq/about/about.html" class="topnav">about dhq</a></span><span><a href="/dhq/people/people.html" class="topnav">dhq people</a></span><span id="rightmost"><a href="/dhq/contact/contact.html" class="topnav">contact</a></span></div><div id="search"><form action="/dhq/findIt" method="get" onsubmit="javascript:document.location.href=cleanSearch(this.queryString.value); return false;"><div><input type="text" name="queryString" size="18"/> <input type="submit" value="Search"/></div></form></div></div></div><div id="main"><div id="leftsidebar"><div id="leftsidenav"><span>Current Issue<br/></span><ul><li><a href="/dhq/vol/11/3/index.html">2017: 11.3</a></li></ul><span>Preview Issue<br/></span><ul><li><a href="/dhq/preview/index.html">2017: 11.4</a></li></ul><span>Previous Issues<br/></span><ul><li><a href="/dhq/vol/11/2/index.html">2017: 11.2</a></li><li><a href="/dhq/vol/11/1/index.html">2017: 11.1</a></li><li><a href="/dhq/vol/10/4/index.html">2016: 10.4</a></li><li><a href="/dhq/vol/10/3/index.html">2016: 10.3</a></li><li><a href="/dhq/vol/10/2/index.html">2016: 10.2</a></li><li><a href="/dhq/vol/10/1/index.html">2016: 10.1</a></li><li><a href="/dhq/vol/9/4/index.html">2015: 9.4</a></li><li><a href="/dhq/vol/9/3/index.html">2015: 9.3</a></li><li><a href="/dhq/vol/9/2/index.html">2015: 9.2</a></li><li><a href="/dhq/vol/9/1/index.html">2015: 9.1</a></li><li><a href="/dhq/vol/8/4/index.html">2014: 8.4</a></li><li><a href="/dhq/vol/8/3/index.html">2014: 8.3</a></li><li><a href="/dhq/vol/8/2/index.html">2014: 8.2</a></li><li><a href="/dhq/vol/8/1/index.html">2014: 8.1</a></li><li><a href="/dhq/vol/7/3/index.html">2013: 7.3</a></li><li><a href="/dhq/vol/7/2/index.html">2013: 7.2</a></li><li><a href="/dhq/vol/7/1/index.html">2013: 7.1</a></li><li><a href="/dhq/vol/6/3/index.html">2012: 6.3</a></li><li><a href="/dhq/vol/6/2/index.html">2012: 6.2</a></li><li><a href="/dhq/vol/6/1/index.html">2012: 6.1</a></li><li><a href="/dhq/vol/5/3/index.html">2011: 5.3</a></li><li><a href="/dhq/vol/5/2/index.html">2011: 5.2</a></li><li><a href="/dhq/vol/5/1/index.html">2011: 5.1</a></li><li><a href="/dhq/vol/4/2/index.html">2010: 4.2</a></li><li><a href="/dhq/vol/4/1/index.html">2010: 4.1</a></li><li><a href="/dhq/vol/3/4/index.html">2009: 3.4</a></li><li><a href="/dhq/vol/3/3/index.html">2009: 3.3</a></li><li><a href="/dhq/vol/3/2/index.html">2009: 3.2</a></li><li><a href="/dhq/vol/3/1/index.html">2009: 3.1</a></li><li><a href="/dhq/vol/2/1/index.html">2008: 2.1</a></li><li><a href="/dhq/vol/1/2/index.html">2007: 1.2</a></li><li><a href="/dhq/vol/1/1/index.html">2007: 1.1</a></li></ul><span>Indexes<br/></span><ul><li><a href="/dhq/index/title.html"> Title</a></li><li><a href="/dhq/index/author.html"> Author</a></li></ul></div><img src="/dhq/common/images/lbarrev.png" style="margin-left : 7px;" alt="sidenavbarimg"/><div id="leftsideID"><b>ISSN 1938-4122</b><br/></div><div class="leftsidecontent"><h3>Announcements</h3><ul><li><a href="/dhq/announcements/index.html#reviewers">Call for Reviewers</a></li><li><a href="/dhq/announcements/index.html#submissions">Call for Submissions</a></li></ul></div><div class="leftsidecontent"><script type="text/javascript">addthis_pub  = 'dhq';</script><a href="http://www.addthis.com/bookmark.php" onmouseover="return addthis_open(this, '', '[URL]', '[TITLE]')" onmouseout="addthis_close()" onclick="return addthis_sendto()"><img src="http://s9.addthis.com/button1-addthis.gif" width="125" height="16" alt="button1-addthis.gif"/></a><script type="text/javascript" src="http://s7.addthis.com/js/152/addthis_widget.js">&lt;!-- Javascript functions --&gt;</script></div></div><div id="mainContent"><div id="printSiteTitle">DHQ: Digital Humanities Quarterly</div><div xmlns:dhqBiblio="http://digitalhumanities.org/dhq/ns/biblio" class="DHQarticle"><div id="pubInfo">2017<br/>Volume 11 Number 2</div><div class="toolbar"><form id="taporware" action="get"><div><a href="/dhq/vol/11/2/index.html">2017 11.2</a>
                     | 
                    <a rel="external" href="/dhq/vol/11/2/000288.xml">XML</a>

| 
		   Discuss
			(<a href="/dhq/vol/11/2/000288/000288.html#disqus_thread" data-disqus-identifier="000288">
				Comments
			</a>)
                </div></form></div>
    <div class="DHQheader">
        
            
                
                <h1 class="articleTitle lang en">OCR of historical printings with an application to building
                    diachronic corpora: A case study using the RIDGES herbal corpus</h1>
                <div class="author"><a rel="external" href="../bios.html#springmann_uwe">Uwe Springmann</a> &lt;<a href="mailto:uwe_dot_springmann_at_hu-berlin_dot_de" onclick="javascript:window.location.href='mailto:'+deobfuscate('uwe_dot_springmann_at_hu-berlin_dot_de'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('uwe_dot_springmann_at_hu-berlin_dot_de'); return false;">uwe_dot_springmann_at_hu-berlin_dot_de</a>&gt;, LMU Munich &amp; Humboldt-Universität zu
                        Berlin</div>
                <div class="author"><a rel="external" href="../bios.html#lüdeling_anke">Anke Lüdeling</a> &lt;<a href="mailto:anke_dot_luedeling_at_rz_dot_hu-berlin_dot_de" onclick="javascript:window.location.href='mailto:'+deobfuscate('anke_dot_luedeling_at_rz_dot_hu-berlin_dot_de'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('anke_dot_luedeling_at_rz_dot_hu-berlin_dot_de'); return false;">anke_dot_luedeling_at_rz_dot_hu-berlin_dot_de</a>&gt;, Humboldt-Universität zu Berlin</div>
            
            
            
        
        
        
        
    <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=OCR%20of%20historical%20printings%20with%20an%20application%20to%20building%20diachronic%20corpora%3A%20A%20case%20study%20using%20the%20RIDGES%20herbal%20corpus&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=2017-02-20&amp;rft.volume=011&amp;rft.issue=2&amp;rft.aulast=Springmann&amp;rft.aufirst=Uwe&amp;rft.au=Uwe%20Springmann&amp;rft.au=Anke%20Lüdeling"> </span></div>
    <div id="DHQtext">
        
            <div id="abstract"><h2>Abstract</h2>
                
                <p>This article describes the results of a case study that applies Neural
                    Network-based Optical Character Recognition (OCR) to scanned images of books
                    printed between 1487 and 1870 by training the OCR engine OCRopus [<a class="ref" href="#breuel2013">Breuel et al. 2013</a>] on the RIDGES herbal text corpus [<a class="ref" href="#odebrecht2017">Odebrecht et al. 2017</a>] (in press). Training specific OCR models was
                    possible because the necessary <em class="term">ground truth</em> is available as
                    error-corrected diplomatic transcriptions. The OCR results have been evaluated
                    for accuracy against the ground truth of unseen test sets. Character and word
                    accuracies (percentage of correctly recognized items) for the resulting
                    machine-readable texts of individual documents range from 94% to more than 99%
                    (character level) and from 76% to 97% (word level). This includes the earliest
                    printed books, which were thought to be inaccessible by OCR methods until
                    recently. Furthermore, OCR models trained on one part of the corpus consisting
                    of books with different printing dates and different typesets (<em class="term">mixed
                        models</em>) have been tested for their predictive power on the books from
                    the other part containing yet other fonts, mostly yielding character accuracies
                    well above 90%. It therefore seems possible to construct generalized models
                    trained on a range of fonts that can be applied to a wide variety of historical
                    printings still giving good results. A moderate postcorrection effort of some
                    pages will then enable the training of individual models with even better
                    accuracies. Using this method, diachronic corpora including early printings can
                    be constructed much faster and cheaper than by manual transcription. The OCR
                    methods reported here open up the possibility of transforming our printed
                    textual cultural heritage into electronic text by largely automatic means, which
                    is a prerequisite for the mass conversion of scanned books.</p>
            </div>
            
        
        
            <div class="div div0">
                <h1 class="head">1. Introduction</h1>
                <div class="counter"><a href="#p1">1</a></div><div class="ptext" id="p1">This paper describes a procedure for converting images of historical printings to
                    electronic text with high accuracies, ranging from 94% to 99% (character
                    accuracies) and 76% to 97% (word accuracies) on our test corpus, by applying
                    Neural Network-based Optical Character Recognition (OCR). The possibility to OCR
                    historical printings with the same relative ease as more recent printings from
                    the 20th century onward would be highly welcome to all researchers who have to
                    deal with source materials from these periods. By historical printings we mean
                    all documents from the beginning of modern printing in 1450 to the 19th
                    century.</div>
                <div class="counter"><a href="#p2">2</a></div><div class="ptext" id="p2">Optical Character Recognition (OCR) for modern printed texts using the Latin
                    alphabet works very well and is often considered a solved problem [<a class="ref" href="#doermann2014">Doermann et al. 2014</a>, 256]. Traditional OCR methods available in
                    commercial and open source software products work as follows: During the OCR
                    process, an image of a printed page is segmented into characters which are then
                    compared to abstract feature sets describing prototypical characters learned
                    previously from a set of trained fonts. The similarity of learned and recognized
                    fonts, the clear separation of uniformly black characters and white spotless
                    background, and modern standardized spelling of the printed words all contribute
                    to excellent recognition results.</div>
                <div class="counter"><a href="#p3">3</a></div><div class="ptext" id="p3">This is, however, not true for early printings because of non-standard
                    typography, highly variable spelling preventing automatic lexical correction
                    during the OCR process, and physical degradation of the pages due to aging and
                    usage (see Figure 1 for two typical examples of pages from the RIDGES corpus, a
                    diachronic corpus of herbal texts in German, which will be described in more
                    detail in Section 3).</div>
                <div class="counter"><a href="#p4">4</a></div><div class="ptext" id="p4">Historical typography alone poses a severe limit for the effectiveness of OCR:
                    All available OCR engines have been extensively trained on modern fonts, but
                    since historical fonts are very different from modern ones and the engines
                    cannot be trained very well by end users on these historical fonts, training on
                    modern fonts has very limited value for the OCR of historical printings. Even
                    for relatively late (i.e. 19th century) texts, OCR results (especially for the
                    multitude of highly variable <em class="term">broken</em> blackletter typefaces) from
                    commercial OCR engines are often less than satisfactory [<a class="ref" href="#piotrowski2012">Piotrowski 2012</a>]
                    [<a class="ref" href="#strange2014">Strange et al. 2014</a>]. Even the more regular Antiqua typefaces (Roman
                    glyph shapes) of historical printings often lead to character accuracies of only
                    around 85% when they are OCRed with <a class="ref" href="http://https://www.abbyy.com/finereader/" onclick="window.open('http://https://www.abbyy.com/finereader/'); return false">ABBYY Finereader</a>, a
                    leading commercial product [<a class="ref" href="#reddy2006">Reddy and Crane 2006</a>]
                    [<a class="ref" href="#springmann2014">Springmann et al. 2014</a>]. Tanner, Muñoz, and Ros (2009) report their
                    experience from the British Libary's <a class="ref" href="http://www.bl.uk/reshelp/findhelprestype/news/newspdigproj/database/index.html" onclick="window.open('http://www.bl.uk/reshelp/findhelprestype/news/newspdigproj/database/index.html'); return false">19th Century Online Newspaper Archive</a> and state that character
                    accuracies greater than 95% are "more usual for post-1900 and pre-1950's text and
                            anything pre-1900 will be fortunate to exceed 85% accuracy."
                         [<a class="ref" href="#tanner2009">Tanner et al. 2009</a>]<a class="noteRef" href="#d7924e247">[1]</a>
                    <em class="term">Incunabula</em>, as the earliest texts (printed from 1450 to 1500), have
                    been deemed to be completely unsuitable for OCR methods [<a class="ref" href="#rydbergcox2009">Rydberg-Cox 2009</a>]<a class="noteRef" href="#d7924e256">[2]</a>.</div>
                <div class="figure">
                    
                    <div class="ptext"><a href="resources/images/figure01.jpg" rel="external"><img src="resources/images/figure01.jpg" alt=""/></a></div>
                <div class="caption"><div class="label">Figure 1. </div>Two page examples of early printings (left: Libavius 1603; right: Curioser
                        Botanicus, 1675) illustrating barriers to OCR: text mixed with images,
                        historical fonts, bleed-through from back page (left), bad contrast
                        (right).</div></div>
                <div class="counter"><a href="#p5">5</a></div><div class="ptext" id="p5">The constraint that OCR engines only give good results on a fixed set of
                    pre-trained fonts can be lifted by the fully trainable open-source OCR engines
                        <a class="ref" href="https://github.com/tesseract-ocr/tesseract" onclick="window.open('https://github.com/tesseract-ocr/tesseract'); return false">Tesseract</a> and
                        <a class="ref" href="https://github.com/tmbdev/ocropy" onclick="window.open('https://github.com/tmbdev/ocropy'); return false">OCRopus</a>. There are two
                    ways of training, namely training on synthetic data (images generated from
                    existing electronic text and available computer fonts), or training on real data
                    (scans and their transcriptions). The first method obviates the need to generate
                        <em class="term">ground truth</em> data by diplomatic transcriptions (a recording of
                    glyph shapes as they appear on a page, with no or minimal editorial
                    interpretation) which are needed to establish the link from glyph shapes to
                    characters during the training process, and one also does not need to preprocess
                    real images. As the complete training process can be automated, this training
                    method is the preferred one whenever it is applicable. However, the multitude of
                    historical fonts is not matched by existing computer fonts, and the
                    irregularities of word spacing in real printings lead to inferior recognition
                    results compared to training on real data [<a class="ref" href="#springmann2014">Springmann et al. 2014</a>]. OCR
                    training for historical printings therefore has to rely on a training process
                    using real data, which means that diplomatic transcriptions of printed images
                    become a key resource. Unfortunately, diplomatically transcribed historical
                    corpora which could serve as training data for historical fonts are not yet
                    available in sufficient quantity. One problem is variability. Earlier
                    typographies are more variable than modern ones because the process of
                    designing, producing and distributing metal letter types (type founding) had not
                    yet become a profession of its own, and early printers had to produce their own
                    typesets leading to a large variety of historical fonts. It is therefore
                    problematic to learn the associations between printed glyphs and the characters
                    they represent from one printing and apply them to the next.</div>
                <div class="counter"><a href="#p6">6</a></div><div class="ptext" id="p6">The problem of applying OCR methods to historical printings is thus twofold.
                    First one needs to train an individual model for a specific book with its
                    specific typography. This can be achieved by transcribing some portion of the
                    printed text, which usually requires linguistic knowledge. Second, even if this
                    model works well for the book it has been trained on, it does not normally
                    produce good OCR results for other books, even if their fonts look similar to
                    the human eye. We need to overcome this <em class="term">typography barrier</em> in order
                    to use OCR methods effectively in the building of a historical electronic text
                    corpus.</div>
                <div class="counter"><a href="#p7">7</a></div><div class="ptext" id="p7">In the following we will describe our experiments addressing both problems.
                    First, we describe a procedure for training <em class="term">individual models</em>,
                    using a new recognition algorithm based upon recurrent neural nets as
                    implemented in the open-source OCR engine OCRopus [<a class="ref" href="#breuel2013">Breuel et al. 2013</a>].
                    As training material we use the readily available scans from library
                    digitization programs and the transcriptions from the RIDGES corpus. The
                    individual model is trained on a single document with its specific fonts and
                    word distances and therefore optimally adapted to this specific book. These
                    models yield the best recognition results for the unseen pages of the books for
                    which they have been trained, but unfortunately give mostly poor results on any
                    other books. Then we explore the viability of training <em class="term">mixed models</em>
                    on a range of different typographies, pooling the training material from a
                    variety of books, with the hope that these models are able to better generalize
                    to other books that had no representation in the training pool. All models, even
                    the individual ones, only get tested on test sets that have no overlap with the
                    training material that was used in model training.</div>
                <div class="counter"><a href="#p8">8</a></div><div class="ptext" id="p8">The remainder of this paper is organized as follows: The current state of the art
                    in historical OCR is related in Section 2. As we will illustrate and evaluate
                    our method on the RIDGES corpus we will briefly describe it in the Section 3.
                    Section 4 details our procedure for training individual models for a subset of
                    20 books printed in broken (blackletter) typefaces, which were used extensively
                    in German printing well into the 20th century. In Section 5 we present the
                    training results and discuss the need for building generalized (mixed) models.
                    Section 6 reports on our experiments to construct mixed models and their
                    performance on unseen books. In Section 7 we dicuss the significance of our
                    results for the building of historical corpora and Section 8 concludes with a
                    summary.</div>
            </div>
            <div class="div div0">
                <h1 class="head">2. Related work</h1>
                <div class="counter"><a href="#p9">9</a></div><div class="ptext" id="p9">Work on historical OCR by other groups has mostly focused on Tesseract which is
                    trainable on artificial images generated from computer fonts. Training on real
                    data, however, has proven to be difficult, and lead to efforts to reconstruct
                    the original historical font from cut-out glyphs. This has been done by both the
                    Digital Libraries Team of the Poznań Supercomputing and Networking Center [<a class="ref" href="#dudczak2014">Dudczak et al. 2014</a>] with their <a class="ref" href="https://confluence.man.poznan.pl/community/display/WLT/Cutouts+application" onclick="window.open('https://confluence.man.poznan.pl/community/display/WLT/Cutouts+application'); return false">cutouts application</a> (proprietary) and EMOP's <a class="ref" href="http://emop.tamu.edu/outcomes/Franken-Plus" onclick="window.open('http://emop.tamu.edu/outcomes/Franken-Plus'); return false">Franken+ tool</a>
                    (open-source). The latter group has reported<a class="noteRef" href="#d7924e321">[3]</a> that they were able to
                    reach a character accuracy of about 86% on the ECCO document
                        collection<a class="noteRef" href="#d7924e325">[4]</a> and 68% on the <a class="ref" href="http://www.textcreationpartnership.org/tcp-eebo/" onclick="window.open('http://www.textcreationpartnership.org/tcp-eebo/'); return false">EEBO
                        collection</a>. Their OCR results suffer badly from scans of binarized
                    microfilm images containing a lot of noise.</div>
                <div class="counter"><a href="#p10">10</a></div><div class="ptext" id="p10">The <a class="ref" href="http://kallimachos.de/" onclick="window.open('http://kallimachos.de/'); return false">Kallimachos project</a> at Würzburg
                    University did have success with Franken+ to reach character accuracies over 90%
                    for an incunable printing [<a class="ref" href="#kirchner2016">Kirchner et al. 2016</a>], but this method again
                    relies on creating diplomatic transcriptions from scratch for each individual
                    font. Ul-Hasan, Bukhari, and Dengel (2016) proposed a method to circumvent
                    ground truth production by first training Tesseract on a historically
                    reconstructed font [<a class="ref" href="#ulhasan2016">Ul-Hasan et al. 2016</a>]. They then applied the resulting
                    model to a specific book and used the recognized text as pseudo-ground truth to
                    train OCRopus. The newly recognized text was again used as pseudo-ground truth
                    for another round of OCRopus training, and after a few iterations they also
                    achieved character accuracies above 93%, but their method shifts the effort to
                    the manual (re)construction of the printed font. Training OCRopus with erroneous
                    OCR recognition as pseudo-ground truth was also tried as one of several methods
                    to improve OCR quality in Springmann, Fink, and Schulz [<a class="ref" href="#springmann2016b">Springmann et al. 2016</a>] but was always found to yield inferior results
                    compared to training on even a small amount of real ground truth at the order of
                    100 to 200 printed lines which consistently lead to character accuracies above
                    95%.</div>
                <div class="counter"><a href="#p11">11</a></div><div class="ptext" id="p11">A completely different approach was taken with the new Ocular OCR engine by
                    Berg-Kirkpatrick, Durrett, and Klein (2013) and Berg-Kirkpatrick and Klein
                    (2014) which is able to convert printed to electronic text in a completely
                    unsupervised manner (i.e., no ground truth is needed) employing a language,
                    typesetting, inking, and noise model [<a class="ref" href="#bergkirkpatrick2013">Berg-Kirkpatrick et al. 2013</a>]
                    [<a class="ref" href="#bergkirkpatrick2014">Berg-Kirkpatrick and Klein 2014</a>]. This may be a viable alternative for
                    training individual models with low manual effort, but it seems to be very
                    resource-intensive and slow (transcribing 30 lines of text in 2.4 min) [<a class="ref" href="#bergkirkpatrick2014">Berg-Kirkpatrick and Klein 2014</a>]. Its results are better than (untrained)
                    Tesseract and ABBYY, but it remains to be shown that they can consistently reach
                    character accuracies higher than 90%.</div>
                <div class="counter"><a href="#p12">12</a></div><div class="ptext" id="p12">In summary, while there are other approaches to train individual OCR models for
                    the recognition of historical documents, so far none have reported results as
                    good as OCRopus when trained on real data (consistently over 94% character
                    accuracy), nor has it been shown that one could construct generalized models
                    applicable to a variety of books with reasonable results (above 90% character
                    accuracy).</div>
            </div>
            <div class="div div0">
                <h1 class="head">3. Diachronic Corpora and RIDGES</h1>
                <div class="counter"><a href="#p13">13</a></div><div class="ptext" id="p13">Our method is evaluated using a <em class="term">diachronic</em> corpus because diachronic
                    corpora with their extremely high variability are a good test case for the
                    training and application of our OCR models. Many historical corpora are
                    basically <em class="term">synchronic</em>, covering a given linguistic period.<a class="noteRef" href="#d7924e373">[5]</a> In
                    addition to these synchronic corpora, there is a small number of diachronic
                    corpora built specifically to do research on change phenomena. Over and above
                    the variation that comes through different dialects, traditions, text types,
                    etc. which is present in any corpus, there is variation that is caused by
                    linguistic and extralinguistic change. The construction of diachronic corpora is
                    subject to all the problems and decisions faced in the construction of
                    synchronic historical corpora, such as corpus design decisions in a situation
                    where many text types or dialects are simply not available, issues of choosing
                    the "original text" (e.g. manuscript/print or edition), and
                    questions of tokenization, normalization, or annotation, etc. (see [<a class="ref" href="#rissanen1989">Rissanen 1989</a>]
                    [<a class="ref" href="#ludeling2004">Lüdeling et al. 2004</a>]
                    [<a class="ref" href="#rissanen2008">Rissanen 2008</a>]
                    [<a class="ref" href="#archer2015">Archer et al. 2015</a>]
                    [<a class="ref" href="#gippert2015">Gippert and Gehrke 2015</a>] among many others). Linguistic changes that make
                    the construction of diachronic corpora more difficult are, among many others,
                    changes in spelling, changes in word formation, or changes in syntax such as
                    changes in word order.</div>
                <div class="counter"><a href="#p14">14</a></div><div class="ptext" id="p14">Extralinguistic changes that might prove problematic include the change of medium
                    (manuscript, print), but also changes within a medium such as different scripts,
                    changing conventions with respect to layout, abbreviations, inclusion of images,
                    the development of technical equipment (i.e. the printing press) or paper
                    quality as well as the development of science with its methods and conventions,
                    the foundation of universities and the addition of new areas of research [<a class="ref" href="#eisenstein1979">Eisenstein 1979</a>]
                    [<a class="ref" href="#weel2011">van der Weel 2011</a>]
                    [<a class="ref" href="#klein1999">Klein 1999</a>].</div>
                <div class="counter"><a href="#p15">15</a></div><div class="ptext" id="p15">Most existing high-quality historical (synchronic and diachronic) corpora are
                    transcribed, collated, and corrected manually, sometimes by (offshore)
                    double-keying transcription. If OCRed text is available for historical prints at
                    all, the quality is typically too low for linguistic studies [<a class="ref" href="#strange2014">Strange et al. 2014</a>]
                    [<a class="ref" href="#piotrowski2012">Piotrowski 2012</a>].</div>
                <div class="counter"><a href="#p16">16</a></div><div class="ptext" id="p16">Manual transcription is time-consuming and expensive and it requires well-trained
                    transcribers. It would therefore be very useful for historical studies to have
                    accesss to high quality OCR.<a class="noteRef" href="#d7924e414">[6]</a> The RIDGES corpus which we use in this article to test our
                    methods is being constructed for research on the development of the scientific
                    register in German (similar corpora are available for English, see e.g. the
                    corpora constructed by the <a class="ref" href="http://www.helsinki.fi/varieng/about/index.html" onclick="window.open('http://www.helsinki.fi/varieng/about/index.html'); return false">Varieng group</a>
                    in Helsinki). It contains herbal texts from between the earliest printings to
                    about 1900. Herbal texts are chosen because they are available throughout the
                    history of German (see e.g. [<a class="ref" href="#riecke2004">Riecke 2004</a>]
                    [<a class="ref" href="#gloning2007">Gloning 2007</a>]) and are among the earliest scientific texts that
                    are available in a vernacular language in Europe. These texts are often
                    compilations or loose translations or transmissions from Latin herbal compendia
                    (transmitting authoritative texts from famous physicians such as Dioscorides,
                    Galen, or Avicenna) and can be viewed as predecessors of scientific and popular
                    texts about plants and illnesses [<a class="ref" href="#habermann2003">Habermann 2003</a>]
                    [<a class="ref" href="#klein2011">Klein 2011</a>].</div>
                <div class="counter"><a href="#p17">17</a></div><div class="ptext" id="p17">The current version of RIDGES (5.0)<a class="noteRef" href="#d7924e440">[7]</a>
                    contains excerpts (about 30 pages each) from 33 different books roughly spaced
                    between 1487 and 1914. The originals are very different from each other in
                    appearance. The earliest texts are mostly collections of "herbal
                        monographs", that is descriptions of a given herb with respect to
                    its properties according to the theory of humoral pathology, its medical
                    indications, and ways of preparation for treatment. Starting in the 16th
                    century, we increasingly find botanical facts. Later texts show greater variety.
                    Some are clearly botanical or medical, others are more in the realm of popular
                    science. Because RIDGES is used for register studies, it is necessary to analyse
                    and annotate many different properties (lexical, morphological, syntactic,
                    structural, etc.) of each text [<a class="ref" href="#biber2009">Biber and Conrad 2009</a>]. The corpus is
                    consequently stored in a multilayer architecture; annotation layers can be added
                    at any time [<a class="ref" href="#krause2016">Krause and Zeldes 2016</a>]. The texts are transcribed
                    diplomatically, normalized on several layers, and annotated deeply (some of the
                    texts contain as many as 53 annotation layers).</div>
                <div class="counter"><a href="#p18">18</a></div><div class="ptext" id="p18">For our present purpose, the most important layer is the diplomatic transcription
                    which serves as training material (<em class="term">ground truth</em>) for the OCR engine
                    (see below), and we want to briefly explain the decisions we took to prepare the
                    diplomatic layer. For all the texts in RIDGES, scans are available from
                    libraries (mostly from <a class="ref" href="http://www.digitale-sammlungen.de/index.html?c=digitale_sammlungen&amp;l=en" onclick="window.open('http://www.digitale-sammlungen.de/index.html?c=digitale_sammlungen&amp;l=en'); return false">Bavarian State Library</a>) or from other sources such as <a class="ref" href="https://books.google.de/" onclick="window.open('https://books.google.de/'); return false">Google Books</a>. Early texts are
                    transcribed manually by students and collated and corrected by other students
                    and researchers; for later texts it is sometimes faster to correct existing OCR
                    results available from library digitization programs or Google Books. The
                    transcription is highly diplomatic - differences between letter forms (like
                        <em class="term">ſ</em> and <em class="term">s</em>) are preserved as well as abbreviation
                    signs (e.g. <em class="term">vñ</em> for modern German <em class="term">und</em>,
                        <em class="term">modoꝝ</em> for <em class="term">modorum</em> with Latin abbreviation
                        <em class="term">ꝝ</em>), or other special characters. Words broken up at a line
                    break are also broken up in the transcription. Layout information (line breaks,
                    page breaks, etc.), information about typefaces (Antiqua, broken fonts), and
                    rendering (colors, spaced type, etc.) are provided in the annotation.</div>
            </div>
            <div class="div div0">
                <h1 class="head">4. Training the OCR engine on historical printings</h1>
                <div class="counter"><a href="#p19">19</a></div><div class="ptext" id="p19">Our training procedure is based on the OCRopus software which was the first OCR
                    engine with a recognition algorithm based on <em class="term">recurrent neural nets</em>
                    (RNNs) with long short-term memory (LSTM) [<a class="ref" href="#hochreiter1997">Hochreiter and Schmidhuber 1997</a>].<a class="noteRef" href="#d7924e505">[8]</a> The LSTM architecture
                    overcomes the problem of earlier neural networks to forget previously learned
                    information and has proven to be very successful in pattern recognition tasks
                    such as handwriting recognition [<a class="ref" href="#graves2009">Graves et al. 2009</a>], even in the context
                    of medieval manuscripts ([<a class="ref" href="#fischer2009">Fischer et al. 2009</a>] got a word accuracy of 93%
                    on isolated words). Models trained with lots of computer fonts led to excellent
                    recognition results for 19th and 20th century printings of Antiqua and Fraktur
                    (blackletter) typefaces with accuracies above 98.5% [<a class="ref" href="#breuel2013">Breuel et al. 2013</a>].
                    As mentioned in the introduction, for earlier printings it is necessary to train
                    on real data. Images of printed lines have to be matched with their
                    corresponding transcriptions (see Figure 2). Unicode character codes for unusual
                    historical characters are available due to the efforts of the <a class="ref" href="http://folk.uib.no/hnooh/mufi/" onclick="window.open('http://folk.uib.no/hnooh/mufi/'); return false">Medieval Unicode Font
                        Initiative</a>.</div>
                <div class="counter"><a href="#p20">20</a></div><div class="ptext" id="p20">The segmentation of the image of a printed page into single text lines is part of
                    a preprocessing step that also involves other functions such as deskewing,
                    border cropping, converting colored page images into binary or grayscale, and
                    some denoising. While OCRopus has its own routines for doing that, they are
                    rather basic and we used the open source program <a class="ref" href="http://scantailor.org/" onclick="window.open('http://scantailor.org/'); return false">ScanTailor</a> for producing clean
                    TIF-images of text regions that were subsequently cut into text lines by the
                    OCRopus subprogram <em class="term">ocropus-gpageseg</em>.</div>
                <div class="figure">
                    
                    <div class="ptext"><a href="resources/images/figure02.png" rel="external"><img src="resources/images/figure02.png" alt=""/></a></div>
                <div class="caption"><div class="label">Figure 2. </div>Pairs of line images and their associated transcriptions needed for
                        training</div></div>
                <div class="counter"><a href="#p21">21</a></div><div class="ptext" id="p21">During training, the OCR engine accesses these image-transcription pairs randomly
                    and learns to associate the inputs (vertical stripes of pixel values) to outputs
                    (characters). Because the line image gets divided into many vertical slices each
                    one pixel wide, there is no need to segment the line further into single glyphs
                    as is usually done by traditional OCR. Instead, the engine learns to associate
                    series of slices corresponding to single glyphs (including ligatures, digraphs,
                    etc., which are not easily segmented from neighboring glyphs) to characters or
                    even character groups automatically (see Figure 3). The cumbersome
                    reconstruction of fonts by cutting out images of the complete glyph repertoire
                    necessary for the training of Tesseract is thus completely avoided.</div>
                <div class="figure">
                    
                    <div class="ptext"><a href="resources/images/figure03.png" rel="external"><img src="resources/images/figure03.png" alt=""/></a></div>
                <div class="caption"><div class="label">Figure 3. </div>The training process in action: The neural network is presented with a
                        printed text line together with its transcription (uppermost panel). The
                        pixel coordinates at the x axis correspond to the vertical slices mentioned
                        in the text. Groups of sequential slices corresponding to a glyph are
                        learned automatically and labelled with the corresponding character from the
                        transcription. The two black panels show the network response to the feeding
                        of the line: the vertical axis represents the type case of the printer and
                        enumerates single characters (about 200), while the horizontal axis again is
                        the pixel width of the line. At each horizontal position, the number of the
                        output character is highlighted. The next panel shows the confidence by
                        which the network recognized the glyphs on a scale from 0 to 1. Blue
                        rectangles correspond to characters, green rectangles to inter-word spaces.
                        The last panel gives the prediction error over training history (over 23,000
                        lines have been seen at this point).</div></div>
                <div class="counter"><a href="#p22">22</a></div><div class="ptext" id="p22">More detailed explanations of the inner workings of neural net training are given
                    in [<a class="ref" href="#breuel2013">Breuel et al. 2013</a>], and a detailed tutorial on how to train models
                    from the user perspective is available in [<a class="ref" href="#springmann2015">Springmann 2015</a>].
                    Special recommendations for training models for incunable printings are given in
                        [<a class="ref" href="#springmann2016a">Springmann and Fink 2016</a>].<a class="noteRef" href="#d7924e556">[9]</a> Springmann, Fink, and
                    Schulz (2016) show that a training set of just 100–200 randomly selected lines
                    with their transcription often results in a model that is almost as good in its
                    performance as more extensive training sets. In this study we used all the
                    available material (i.e. the ca. 30 transcribed pages for each book) and split
                    it into 90% for training and 10% for testing [<a class="ref" href="#springmann2016b">Springmann et al. 2016</a>].</div>
                <div class="counter"><a href="#p23">23</a></div><div class="ptext" id="p23">Every 1,000 learning steps (one step consists in seeing one image-transcription
                    pair) an OCR model is saved to disk, and after having seen each pair about 30
                    times the training process is stopped. The series of models is then evaluated on
                    the test set which has never been seen in training. Evaluation is done by a
                    line-wise comparison of the string of symbols representing the ground truth and
                    the OCR result, and the minimal edit (<em class="term">Levenshtein</em>) distance between
                    these two symbol strings is the number of character errors for this line.
                    Complete error statistics are available from the OCRopus command
                        <em class="term">ocropus-errs</em>. The model with the least error on this test when
                    comparing OCR result and ground truth is then selected as the best one
                    representing the training effort for this book. An example of the resulting OCR
                    text together with the corresponding page image is shown in Figure 4.</div>
                <div class="figure">
                    
                    <div class="ptext"><a href="resources/images/figure04.png" rel="external"><img src="resources/images/figure04.png" alt=""/></a></div>
                <div class="caption"><div class="label">Figure 4. </div>Resulting OCR text from application of a trained model to a previously
                        unseen page (1487 Garten der Gesunthait, errors marked in red).</div></div>
            </div>
            <div class="div div0">
                <h1 class="head">5. OCR results from individually trained models</h1>
                <div class="counter"><a href="#p24">24</a></div><div class="ptext" id="p24">For the training of individual models we have selected the following 20
                        books<a class="noteRef" href="#d7924e589">[10]</a>
                    printed in broken typefaces typical of German historical printings. The printing
                    dates cover a period of almost four centuries, from the incunable printing of
                        <cite class="title italic"><span class="foreign i">Garten der
                        Gesunthait</span></cite> in 1487 to <cite class="title italic"><span class="foreign i">Deutsche Pflanzennamen</span></cite> from 1870 (cf.
                    Table 1).</div>
                <div class="table"><table class="table"><tr class="row">
                        <td valign="top" class="cell label">Year</td>
                        <td valign="top" class="cell label">(Short) Title</td>
                        <td valign="top" class="cell label">Author</td>
                        <td valign="top" class="cell label">Label</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1487</td>
                        <td valign="top" class="cell">Garten der Gesunthait</td>
                        <td valign="top" class="cell">Johannes von Cuba</td>
                        <td valign="top" class="cell">1487-G</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1532</td>
                        <td valign="top" class="cell">Artzney Buchlein der Kreutter</td>
                        <td valign="top" class="cell">Johannes Tallat</td>
                        <td valign="top" class="cell">1532-A</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1532</td>
                        <td valign="top" class="cell">Contrafayt Kreüterbuch</td>
                        <td valign="top" class="cell">Otto Brunfels</td>
                        <td valign="top" class="cell">1532-C</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1543</td>
                        <td valign="top" class="cell">New Kreüterbuch</td>
                        <td valign="top" class="cell">Hieronymus Bock</td>
                        <td valign="top" class="cell">1543-N</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1557</td>
                        <td valign="top" class="cell">Wie sich meniglich</td>
                        <td valign="top" class="cell">Adam von Bodenstein</td>
                        <td valign="top" class="cell">1557-W</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1588</td>
                        <td valign="top" class="cell">Paradeißgärtlein</td>
                        <td valign="top" class="cell">Konrad Rosbach</td>
                        <td valign="top" class="cell">1588-P</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1603</td>
                        <td valign="top" class="cell">Alchymistische Practic</td>
                        <td valign="top" class="cell">Andreas Libavius</td>
                        <td valign="top" class="cell">1603-A</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1609</td>
                        <td valign="top" class="cell">Hortulus Sanitatis</td>
                        <td valign="top" class="cell">Castore Durante</td>
                        <td valign="top" class="cell">1609-H</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1609</td>
                        <td valign="top" class="cell">Kräutterbuch</td>
                        <td valign="top" class="cell">Bartholomäus Carrichter</td>
                        <td valign="top" class="cell">1609-K</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1639</td>
                        <td valign="top" class="cell">Pflantz-Gart</td>
                        <td valign="top" class="cell">Daniel Rhagor</td>
                        <td valign="top" class="cell">1639-P</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1652</td>
                        <td valign="top" class="cell">Wund-Artzney</td>
                        <td valign="top" class="cell">Guilelmus Fabricius Hildanus</td>
                        <td valign="top" class="cell">1652-W</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1673</td>
                        <td valign="top" class="cell">Thesaurus Sanitatis</td>
                        <td valign="top" class="cell">Adrian Nasser</td>
                        <td valign="top" class="cell">1673-T</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1675</td>
                        <td valign="top" class="cell">Curioser Botanicus</td>
                        <td valign="top" class="cell">Anonymous</td>
                        <td valign="top" class="cell">1675-C</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1687</td>
                        <td valign="top" class="cell">Der Schweitzerische Botanicus</td>
                        <td valign="top" class="cell">Timotheus von Roll</td>
                        <td valign="top" class="cell">1687-D</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1722</td>
                        <td valign="top" class="cell">Flora Saturnizans</td>
                        <td valign="top" class="cell">Johann Friedrich Henckel</td>
                        <td valign="top" class="cell">1722-F</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1735</td>
                        <td valign="top" class="cell">Mysterium Sigillorvm</td>
                        <td valign="top" class="cell">Israel Hiebner</td>
                        <td valign="top" class="cell">1735-M</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1764</td>
                        <td valign="top" class="cell">Einleitung zu der Kräuterkenntniß</td>
                        <td valign="top" class="cell">Georg Christian Oeder</td>
                        <td valign="top" class="cell">1764-E</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1774</td>
                        <td valign="top" class="cell">Unterricht von der allgemeinen Kräuter- und Wurzeltrocknung</td>
                        <td valign="top" class="cell">Johann Georg Eisen</td>
                        <td valign="top" class="cell">1774-U</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1828</td>
                        <td valign="top" class="cell">Die Eigenschaften aller Heilpflanzen</td>
                        <td valign="top" class="cell">Anonymous</td>
                        <td valign="top" class="cell">1828-D</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">1870</td>
                        <td valign="top" class="cell">Deutsche Pflanzennamen</td>
                        <td valign="top" class="cell">Hermann Grassmann</td>
                        <td valign="top" class="cell">1870-D</td>
                    </tr></table><div class="caption"><div class="label">Table 1. </div>Books used for training and testing OCR models.</div></div>
                <div class="counter"><a href="#p25">25</a></div><div class="ptext" id="p25">The resulting character and word accuracies for models trained on each book have
                    been evaluated on unseen test pages and are shown in Figure 5. To get an idea of
                    the variance of the measurement values we also indicated upper and lower limits
                    of a 95% confidence interval for character accuracies calculated from the
                    assumption that OCR recognition can be treated as a Bernoulli experiment with
                    the measured accuracy as the probability for correct recognition. For each book,
                    the individual model is able to recognize printed characters with an accuracy of
                    over 94%, sometimes even reaching 99%.</div>
                <div class="counter"><a href="#p26">26</a></div><div class="ptext" id="p26">Word accuracies are also given, as they are important for search and indexing
                    purposes [<a class="ref" href="#tanner2009">Tanner et al. 2009</a>]. We have to keep in mind, though, that
                    early printings show a high variety of spellings and a high word accuracy does
                    not necessarily mean that we find every instance of a correctly recognized word
                    by searching for its modern equivalent. Evaluations of word accuracies were done
                    with the UNLV/ISRI Analytic Tools for OCR Evaluation [<a class="ref" href="#nartker2005">Nartker et al. 2005</a>] adapted for UTF-8 by Nick White.<a class="noteRef" href="#d7924e937">[11]</a> Compared to character accuracies,
                    the word accuracies show a much wider variance, ranging from 76% to 97%. Except
                    for two instances (1675-D and 1687-D), however, all models have word accuracies
                    over 85%, twelve models over 90%, and five even over 95%, resulting in a mean
                    word accuracy of 91%. This is in stark contrast to the newspaper projects
                    reported in Tanner, Muñoz, and Ros (2009) with a mean word accuracy of 78% for
                    the 19th Century Newspaper Project and 65% for the Burney Collection (17th and
                    18th century newspapers) and illustrates the progress in recognition that has
                    become possible through Neural Network-based OCR models [<a class="ref" href="#tanner2009">Tanner et al. 2009</a>].</div>
                <div class="counter"><a href="#p27">27</a></div><div class="ptext" id="p27">The wider variance for word accuracies can be explained by the statistics of
                    single character errors. Assuming that we had 600 characters with 30 errors (95%
                    character accuracy), and that the 600 characters consist of 100 words, the 30
                    character errors could be contained in just 5 words or in 30 words with
                    resulting word accuracies ranging from 95% down to 70%. In the latter case,
                    erroneous words just contain a single character error and a better model with
                    half of the errors would therefore upgrade character accuracy from 95% to 97.5%,
                    but word accuracy would get a much higher boost from 70% to 85%.</div>
                <div class="counter"><a href="#p28">28</a></div><div class="ptext" id="p28">The most striking result reported in Figure 5 is the lack of any correlation
                    between OCR accuracy and printing age. Models for even the earliest printings in
                    our corpus show top performance when the printings were well–preserved and good
                    scans were available.</div>
                <div class="counter"><a href="#p29">29</a></div><div class="ptext" id="p29">These results have been achieved just by recognizing glyph shapes, without
                    employing any language model, lexicon, or postcorrection. This shows that OCR
                    quality does not deteriorate with earlier printing dates but instead depends on
                    the quality of the printings in its currently preserved state and the scans.
                    Lower accuracies point to instrinsic problems on book pages such as manual
                    annotation, speckles, or low resolution (about 150 dpi), especially when
                    downloaded from Google Books. Often a higher resolution of the same book was
                    available from the Bavarian State Library (BSB).<a class="noteRef" href="#d7924e954">[12]</a> Given good printings in well–preserved
                    states, 300 dpi color or gray–scale scans, and an accurate preprocessing of page
                    images into single text lines (see the discussion in Section 7), it is possible
                    to reach character accuracies above 98% in all periods of modern printing. The
                    fact that commercial OCR applications yield increasingly worse results the older
                    the printing just reflects that fact that earlier printings are increasingly
                    different from the fonts the OCR engine has been trained on.</div>
                <div class="figure">
                    
                    <div class="ptext"><a href="resources/images/figure05.png" rel="external"><img src="resources/images/figure05.png" alt=""/></a></div>
                <div class="caption"><div class="label">Figure 5. </div>Character accuracies (blue columns) with 95% confidence intervals and word
                        accuracies (red columns) for models trained on the individual books given in
                        Table 1.</div></div>
                <div class="counter"><a href="#p30">30</a></div><div class="ptext" id="p30">While the above results are very promising, they could only be reached by
                    training an individual model on each book. Using RIDGES, we are in the favorable
                    situation that the necessary ground truth needed for training is available. In
                    general, however, no such transcriptions will exist and this may still prevent
                    the application of OCR to large volumes of scans of historical books in an
                    automatic manner. It is therefore of interest to see how well the existing
                    models generalize to unseen books. To test how the individual models perform on
                    the other books of our selection, we applied each model to each book. The
                    resulting accuracies from this experiment are shown in Figure 6. The rows
                    represent the books, whereas columns designate the models.</div>
                <div class="counter"><a href="#p31">31</a></div><div class="ptext" id="p31">As expected, the best result for each book is provided by its own model. This is
                    mostly true for the models as well, but in one case (1675-C) the trained model
                    performs better on other books with a similar font (1764-E and 1774-U, although
                    not as well as these books' models) than on its own book. The bad performance of
                    1675-C is due to the grayscale images lacking in contrast (see Figure 1). More
                    interesting is the question whether individual models give satisfactory results
                    on any other book. The model for 1675-C is an exception with accuracies over 90%
                    for books printed between 1609 and 1828. If accuracies above 90% are acceptable,
                    models trained on printings from the 17th century seem to be somewhat applicable
                    to printings from the 17th and 18th century, whereas for later, and especially
                    earlier printings, single models do not generalize well. In the next section, we
                    will therefore explore whether mixed models trained on several books will better
                    generalize to unseen books and offer a way to overcome the typography
                    barrier.</div>
                <div class="figure">
                    
                    <div class="ptext"><a href="resources/images/figure06.png" rel="external"><img src="resources/images/figure06.png" alt=""/></a></div>
                <div class="caption"><div class="label">Figure 6. </div>Cross evaluation of each model (column) on each book (row). Character
                        accuracies are color coded in the ranges greater than 95% (green), between
                        90 and 95% (yellow) and below 90% (gray).</div></div>
            </div>
            <div class="div div0">
                <h1 class="head">6. Construction of mixed models</h1>
                <div class="counter"><a href="#p32">32</a></div><div class="ptext" id="p32">We trained two mixed models on a breakdown of our corpus into two parts by
                    choosing every other book as part 1 and the rest as part 2 (Figure 7). Each part
                    covers about 400 years of printing history so that we can test how well a mixed
                    model trained from a sample of books over a wide range of printing dates
                    generalizes to other unseen books dating from the same period.</div>
                <div class="counter"><a href="#p33">33</a></div><div class="ptext" id="p33">The result of applying each of the two mixed models to the books from the other
                    subset is shown in Figure 7 (yellows columns) together with the accuracies of
                    individual models (blue columns). The results are given in terms of both
                    character accuracy (upper panel) and word accuracy (lower panel).</div>
                <div class="counter"><a href="#p34">34</a></div><div class="ptext" id="p34">As may be expected, mixed models give a lower accuracy compared to individual
                    models (with the exception of 1774-U), because mixed models have not been
                    trained on books of the other part to which they have been applied. But except
                    for the two earliest printings and in contrast to Figure 6, both mixed models
                    now consistently reach over 90% character accuracy on books which did not
                    contribute to the training pool. In one case (1774-U) the mixed model shows a
                    slightly better performance than the individual model. This book is similar
                    enough in its typography to the books of the other part on which the mixed model
                    has been trained, so that recognition is improved. The incunable printing of
                    1487 gets the worst recognition from the mixed model because its typography is
                    unlike any other book in the corpus.</div>
                <div class="counter"><a href="#p35">35</a></div><div class="ptext" id="p35">Comparing the difference in character and word accuracies, we see the effect that
                    the improved character accuracies that are obtained from going from a mixed
                    model to an individual model also improve the word accuracies, but by a larger
                    absolute margin (roughly, halving the character errors also halves the word
                    errors; see Table 2).</div>
                <div class="table"><table class="table"><tr class="row">
                        <td valign="top" class="cell label">mean accuracy</td>
                        <td valign="top" class="cell label">Part 1</td>
                        <td valign="top" class="cell label">Part 2</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell"><em class="term">character accuracy</em></td>
                        <td valign="top" class="cell"/>
                        <td valign="top" class="cell"/>
                    </tr><tr class="row">
                        <td valign="top" class="cell">individual models</td>
                        <td valign="top" class="cell">98.07%</td>
                        <td valign="top" class="cell">97.94%</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">mixed model</td>
                        <td valign="top" class="cell">95.81%</td>
                        <td valign="top" class="cell">94.27%</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell"><em class="term">word accuracy</em></td>
                        <td valign="top" class="cell"/>
                        <td valign="top" class="cell"/>
                    </tr><tr class="row">
                        <td valign="top" class="cell">individual models</td>
                        <td valign="top" class="cell">91.53%</td>
                        <td valign="top" class="cell">90.71%</td>
                    </tr><tr class="row">
                        <td valign="top" class="cell">mixed model</td>
                        <td valign="top" class="cell">83.20%</td>
                        <td valign="top" class="cell">76.09%</td>
                    </tr></table><div class="caption"><div class="label">Table 2. </div>Mean accuracies for individual and mixed models</div></div>
                <div class="figure">
                    
                    <div class="ptext"><a href="resources/images/figure07.png" rel="external"><img src="resources/images/figure07.png" alt=""/></a></div>
                <div class="caption"><div class="label">Figure 7. </div>Accuracies of OCR results for individual models (blue) and for a mixed
                        model trained on the other part of the corpus (yellow).</div></div>
                <div class="counter"><a href="#p36">36</a></div><div class="ptext" id="p36">The remaining OCR errors in both the mixed and individual model recognition
                    consist in equal numbers of substitution errors (one character gets confused
                    with another, often similar looking character, such as "e"
                    and "c") and deletion or insertion errors (characters are
                    either not recognized at all or spurious characters are inserted where none were
                    printed). By far the most frequent deleted or inserted character is the blank,
                    which when inserted leads to broken-up words into two or more fragments, or if
                    deleted, leads to merged words where two or more printed words are recognized as
                    a single word. This again underscores the necessity to train a recognition model
                    on real printings, as a proper word distance model can be learned only in this
                    way, and even then the peculiarities of early-modern printing with its emphasis
                    on justified printing lines lead to relatively frequent errors involving the
                    non-character of blanks.</div>
                <div class="counter"><a href="#p37">37</a></div><div class="ptext" id="p37">The training of mixed models does therefore seem to be a way to overcome the
                    typography barrier and it can provide models which generalize well over a wide
                    range of books. The resulting OCR text can at least be taken as a first
                    approximation and better models can be trained from an error corrected version
                    of its recognized text. The same conclusion has been reached in a study on
                    twelve Latin books printed from 1471 to 1686 in Antiqua fonts in Springmann,
                    Fink, and Schulz (2016), where a method is given to construct better individual
                    models with minimal manual effort starting from a mixed model [<a class="ref" href="#springmann2016b">Springmann et al. 2016</a>].</div>
            </div>
            <div class="div div0">
                <h1 class="head">7. Discussion</h1>
                <div class="counter"><a href="#p38">38</a></div><div class="ptext" id="p38">For the practical purpose of historical corpus construction, it is very
                    encouraging to see that we can train OCR models that work very well for even the
                    oldest printings. However, this success comes at the price of necessary training
                    for each new font. The peculiarities of early typesetting requires that we train
                    on real data and we must therefore manually prepare the ground truth for a
                    couple of pages. The resulting trained model will be applicable to all works
                    printed with the same font, which for early printings means the same font of the
                    same typographer's office which may have been used for a whole series of works.
                    The possibility to train mixed models covering a range of historical fonts and
                    periods is a big step forward to convert historical printings to electronic text
                    without having to train an individual model for each text. In the absence of
                    ground truth, one can start with the output of a mixed model and only correct it
                    if needed, so that manual transcription is reduced to a minimum of about 100 to
                    200 text lines [<a class="ref" href="#springmann2016b">Springmann et al. 2016</a>].</div>
                <div class="counter"><a href="#p39">39</a></div><div class="ptext" id="p39">We want to stress that the usefulness of OCR results for research purposes
                    depends not only on recognition quality of perfectly segmented text lines, but
                    also on preprocessing (page segmentation, binarization etc.) and postprocessing
                    steps (error correction, normalization, annotation) which we will discuss in
                    turn.</div>
                <div class="counter"><a href="#p40">40</a></div><div class="ptext" id="p40">Because text recognition happens on single printed lines, we need to segment
                    printed pages into those lines. This is not a trivial task, as many historical
                    printings abound with decorative initials, floral decorations, marginal
                    annotations (printed and manual), and image drawings (see Figure 1). Anything
                    that goes wrong at this preprocessing stage will lead to bad recognition results
                    later. Because the preprocessing routines of the OCR engines are often not able
                    to solve this difficult task in a satisfactory automatic manner there is a need
                    for specific tools which could at least assist a human to semi-automatically
                    segment the page images. ScanTailor is too restricted when the layout becomes
                    too involved with text columns, headings spanning the columns, margins,
                    footnotes, etc. To fill this gap, a new open source tool has been made available
                    (LAREX) that allows the user to quickly interact with the layout, define some
                    general parameters and have a complete document segmented automatically,
                    including the reading order [<a class="ref" href="#reul2017b">Reul et al. 2017b</a>]. Errors occuring in this
                    automatic process can afterwards be amended manually. In a case study treating
                    an incunable printing consisting of almost 800 pages, the complete document
                    could be segmented into text zones by an experienced user in less than six hours
                        [<a class="ref" href="#reul2017a">Reul et al. 2017a</a>].</div>
                <div class="counter"><a href="#p41">41</a></div><div class="ptext" id="p41">On the postprocessing side, we first have to deal with the accuracy of the OCR
                    result. Whether the uncorrected OCR output is sufficient for research or not
                    depends on the specific research interests of a scholar. 95% character accuracy
                    (or 90% word accuracy) may be enough for searching within a work or a corpus,
                    especially if the search is spelling tolerant and if the results are
                    simultaneously highlighted in the scan. Getting a high percentage of possible
                    hits (<em class="term">high recall</em>) is more important than getting a low number of
                    false hits (<em class="term">high precision</em>), because false hits can easily be
                    discarded by looking at the scan. Any true hit will provide the researcher with
                    a piece of evidence he is looking for. For other interests a higher accuracy
                    might be needed and error correction will be necessary. The efficiency of
                    correction will be greatly helped by a tool that presents whole series of
                    statistically induced errors which the user can inspect, select, and correct in
                    a single step. The more common errors can then be corrected with little effort,
                    boosting accuracy and leaving only rare errors for which one still would need to
                    go over the complete text if needed. Such a postcorrection method enabling batch
                    correction of common errors has been developed at the Center for Information and
                    Language Processing of LMU under the name of <a class="ref" href="https://github.com/cisocrgroup/PoCoTo" onclick="window.open('https://github.com/cisocrgroup/PoCoTo'); return false">PoCoTo</a> and is available
                    under an open-source licence [<a class="ref" href="#vobl2014">Vobl et al. 2014</a>]. Furthermore, the tool is
                    able to distinguish between historical spellings and real OCR errors and offers
                    only the latter category for correction. It can import OCR results from ABBYY
                    Finereader (XML), Tesseract (hOCR), and OCRopus (hOCR) and export the corrected
                    text as pure text, XML, hOCR, or TEI.</div>
                <div class="counter"><a href="#p42">42</a></div><div class="ptext" id="p42">But even if we had 100% correct transcriptions from corrected OCR recognition, we
                    would still be hampered by the fact that there is no standardized spelling for
                    historical texts which results in a high degree of variation (the same word can
                    be spelled in several different ways by the same author in the same text).
                    Often, but certainly not always, there is an etymologically related modern word.
                    Depending on the research question, there might be different ways of dealing
                    with meaning change or etymological replacement. Searching then becomes
                    problematic as searches are usually done by entering search terms in modern
                    spelling. One needs to make sure that all tokens with their various historical
                    spellings are found. How this can best be achieved with a combination of modern
                    and historical lexica and a set of historical patterns by which modern and
                    historical wordforms may get connected has been described by Gotscharek et al.
                        [<a class="ref" href="#gotscharek2011">Gotscharek et al. 2011</a>], Ernst-Gerlach and Fuhr [<a class="ref" href="#ernstgerlach2006">Ernst-Gerlach and Fuhr 2006</a>], and Ernst-Gerlach and Fuhr [<a class="ref" href="#ernstgerlach2007">Ernst-Gerlach and Fuhr 2007</a>].</div>
                <div class="counter"><a href="#p43">43</a></div><div class="ptext" id="p43">The current paper only considers the production of OCR recognized text, but for
                    corpus construction one would also like to have methods for automatic
                    normalization of historical texts, so that the expansion of modern wordforms to
                    multiple possible historical wordforms becomes unnecessary, and which would also
                    allow further treatment of corpus texts such as part-of-speech tagging and
                    lemmatization. Work in this direction has been done by Pilz et al. [<a class="ref" href="#pilz2008">Pilz et al. 2008</a>], Baron, Rayson, and Archer [<a class="ref" href="#baron2009">Baron et al. 2009</a>],
                    Bollmann, Petran, and Dipper [<a class="ref" href="#bollmann2011">Bollmann et al. 2011</a>], and Jurish [<a class="ref" href="#jurish2013">Jurish 2013</a>]. The RIDGES corpus contains a special annotation
                    layer with a manually normalized token for each historical token. Normalized
                    layers (which in multi-layer architectures can be provided in addition to the
                    diplomatic layers) allow searches across different spellings (stemming from
                    different authors and times) and can be used as input for automatic tools.
                    Odebrecht et al. (in press) illustrate this using several test cases [<a class="ref" href="#odebrecht2017">Odebrecht et al. 2017</a>]. Weiß and Schnelle (2016) sketch how the
                    normalized layer of RIDGES can be used for automatic parsing [<a class="ref" href="#weiß2016">Weiß and Schnelle 2016</a>].</div>
                <div class="counter"><a href="#p44">44</a></div><div class="ptext" id="p44">Finally, one has too keep in mind that residual recognition errors present in any
                    OCR corpus may exert a bias on research (see [<a class="ref" href="#traub2015">Traub et al. 2015</a>]), so
                    that at least an indication of OCR quality in the absence of any ground truth
                    would be highly desirable to give researchers an idea of what quality they are
                    dealing with. Some work in this direction is reported in Springmann, Fink, and
                    Schulz [<a class="ref" href="#springmann2016b">Springmann et al. 2016</a>].</div>
                <div class="counter"><a href="#p45">45</a></div><div class="ptext" id="p45">To summarize, currently the main obstacles for a machine-assisted construction of
                    historical corpora are the problems of automatic segmentation of page images
                    into text and non-text zones, the recognition of historical fonts, and the
                    postprocessing problems of error correction and normalization. The better we
                    solve the recognition problem by means of trained historical OCR and mixed
                    models, the more prominent the preprocessing (segmentation) and postprocessing
                    (error correction, normalization) problems will become.</div>
            </div>
            <div class="div div0">
                <h1 class="head">8. Summary and Conclusion</h1>
                <div class="counter"><a href="#p46">46</a></div><div class="ptext" id="p46">We have shown that the new trainable OCR method based upon LSTM RNNs can provide
                    high recognition accuracies (character accuracies from 95% to over 99%, word
                    accuracies from 76% to 97%) for images of early printings regardless of their
                    age, provided good scans are available. An OCR model trained on the diplomatic
                    transcription of some pages can be used for the recognition of the rest of the
                    book and leads to electronic text whose quality may already be sufficient for
                    many research questions. The availability of generalized models trained on a
                    mixture of fonts would further ease the use of OCR on historical documents, as
                    the output of these mixed models can be taken as a first approximation to a true
                    representation of the text and may be corrected (and better models trained on
                    it) if needed. The models trained on RIDGES have been used to recognize whole
                    books and thus led to an expanded, if somewhat inaccurate, electronic corpus.
                    Both this corpus (named RIDGES-OCR) and the above mentioned mixed models are
                    available under CC-BY.<a class="noteRef" href="#d7924e1191">[13]</a>
                    As more and more diplomatically transcribed texts (either manually transcribed
                    or recognised by OCR methods) become available, their usability as a corpus for
                    research purposes will depend on automatic means to normalize historical
                    spelling (even in the presence of OCR errors) enabling both search and indexing
                    as well as further analysis such as part-of-speech tagging and
                        lemmatization.<a class="noteRef" href="#d7924e1196">[14]</a></div>
            </div>
            <div class="div div0">
                <h1 class="head">Acknowledgements</h1>
                <div class="counter"><a href="#p47">47</a></div><div class="ptext" id="p47">This work was partially funded by Deutsche Forschungsgemeinschaft (DFG) under
                    grant no. LU 856/7-1.</div>
            </div>
        
        
            
        
    </div>
<div id="notes"><h2>Notes</h2><div class="endnote" id="d7924e247"><span class="noteRef">[1]</span>
                        <a class="ref" href="http://www.dlib.org/dlib/july09/munoz/07munoz.html" onclick="window.open('http://www.dlib.org/dlib/july09/munoz/07munoz.html'); return false">http://www.dlib.org/dlib/july09/munoz/07munoz.html</a></div><div class="endnote" id="d7924e256"><span class="noteRef">[2]</span>
                        <a class="ref" href="ttp://digitalhumanities.org/dhq/vol/3/1/000027/000027.html#p7" onclick="window.open('ttp://digitalhumanities.org/dhq/vol/3/1/000027/000027.html#p7'); return false">http://digitalhumanities.org/dhq/vol/3/1/000027/000027.html#p7</a></div><div class="endnote" id="d7924e321"><span class="noteRef">[3]</span><a class="ref" href="http://emop.tamu.edu/final-report" onclick="window.open('http://emop.tamu.edu/final-report'); return false">http://emop.tamu.edu/final-report</a></div><div class="endnote" id="d7924e325"><span class="noteRef">[4]</span>Eighteenth Century Collections Online, <a class="ref" href="http://quod.lib.umich.edu/e/ecco/" onclick="window.open('http://quod.lib.umich.edu/e/ecco/'); return false">http://quod.lib.umich.edu/e/ecco/</a></div><div class="endnote" id="d7924e373"><span class="noteRef">[5]</span>
                        Basically, even the so-called synchronic corpora for older language stages
                        are often diachronic, covering a long period of time; examples are the
                        reference corpora in the DeutschDiachronDigital project, such as the
                        Referenzkorpus Altdeutsch (<a class="ref" href="http://www.deutschdiachrondigital.de/home/" onclick="window.open('http://www.deutschdiachrondigital.de/home/'); return false">http://www.deutschdiachrondigital.de/home/</a>) or the Old and Middle
                        English Corpora listed at <a class="ref" href="http://users.ox.ac.uk/~stuart/english/med/corp.htm" onclick="window.open('http://users.ox.ac.uk/~stuart/english/med/corp.htm'); return false">http://users.ox.ac.uk/~stuart/english/med/corp.htm</a></div><div class="endnote" id="d7924e414"><span class="noteRef">[6]</span> While our focus here is on linguistic
                        research questions it is obvious and has been argued many times (see e.g.,
                        the DFG Practical Guidelines on Digitisation [02/13], p. 29; <a class="ref" href="http://www.dfg.de/formulare/12_151/" onclick="window.open('http://www.dfg.de/formulare/12_151/'); return false">http://www.dfg.de/formulare/12_151/</a>) that the better the OCR
                        quality, the more useful the resulting text is for any kind of research. The
                        re-usability of corpora has been an issue in many recent endeavours (cf.
                            [<a class="ref" href="#ludeling2008">Lüdeling and Zeldes 2008</a>]
                        [<a class="ref" href="#geyken2015">Geyken and Gloning 2015</a>], among many others) but cannot be discussed
                        here.</div><div class="endnote" id="d7924e440"><span class="noteRef">[7]</span>
                        <a class="ref" href="http://korpling.german.hu-berlin.de/ridges/index_en.html" onclick="window.open('http://korpling.german.hu-berlin.de/ridges/index_en.html'); return false">http://korpling.german.hu-berlin.de/ridges/index_en.html</a>. The
                        corpus is freely available under the CC-BY license. It can be downloaded in
                        several formats as well as queried through the ANNIS search tool [<a class="ref" href="#krause2016">Krause and Zeldes 2016</a>]. The corpus is still growing. Here we focus only
                        on the first step in corpus compilation. More on meta-data, annotation, and
                        analysis can be found in [<a class="ref" href="#odebrecht2017">Odebrecht et al. 2017</a>] (in press).</div><div class="endnote" id="d7924e505"><span class="noteRef">[8]</span>Tesseract in its upcoming version 4 also uses long short-term
                        memory (LSTM) networks, but its training procedure is quite resource
                        intensive and there is not yet any documentation available on how to train a
                        recognition model on real printed images.</div><div class="endnote" id="d7924e556"><span class="noteRef">[9]</span>
                        <a class="ref" href="http://www.cis.lmu.de/ocrworkshop" onclick="window.open('http://www.cis.lmu.de/ocrworkshop'); return false">http://www.cis.lmu.de/ocrworkshop</a></div><div class="endnote" id="d7924e589"><span class="noteRef">[10]</span>Sources are given at <a class="ref" href="http://korpling.german.hu-berlin.de/ridges/download_v5.0_en.html" onclick="window.open('http://korpling.german.hu-berlin.de/ridges/download_v5.0_en.html'); return false">http://korpling.german.hu-berlin.de/ridges/download_v5.0_en.html</a>.</div><div class="endnote" id="d7924e937"><span class="noteRef">[11]</span>Available from <a class="ref" href="https://ancientgreekocr.org/" onclick="window.open('https://ancientgreekocr.org/'); return false">https://ancientgreekocr.org/</a></div><div class="endnote" id="d7924e954"><span class="noteRef">[12]</span>E.g., a retraining on the
                        BSB scan of the same exemplar of Bodenstein's 1557 book increased the
                        accuracy from 95% to 99%.</div><div class="endnote" id="d7924e1191"><span class="noteRef">[13]</span>
                        <a class="ref" href="https://www.linguistik.hu-berlin.de/en/institut-en/professuren-en/korpuslinguistik/research/ridges-projekt/ocr?set_language=en" onclick="window.open('https://www.linguistik.hu-berlin.de/en/institut-en/professuren-en/korpuslinguistik/research/ridges-projekt/ocr?set_language=en'); return false">https://www.linguistik.hu-berlin.de/en/institut-en/professuren-en/korpuslinguistik/research/ridges-projekt/ocr?set_language=en</a></div><div class="endnote" id="d7924e1196"><span class="noteRef">[14]</span>It would be very beneficial if a consortium of libraries
                        would set up a central repository for trained models that would otherwise
                        end up on the hard disks of individual users and not be available for others
                        who would unnecessarily need to train the same model again. Even better, the
                        complete training procedure could be made available via a web interface
                        which allows the user to transcribe some pages as ground truth, train a
                        model (possibly through several refinement steps as explained above), and at
                        the end provide the user with the recognized text in some marked-up format
                        as well as adding the model and ground truth to the repository. That way
                        both the individual user and the community at large would benefit from an
                        ever-increasing amount of ground truth, corresponding image data and trained
                        models.</div></div><div id="worksCited"><h2>Works Cited</h2><div class="bibl"><span class="ref" id="archer2015"><!-- close -->Archer et al. 2015</span> Archer, Dawn, Merja Kytö,
                    Alistair Baron, and Paul Rayson. 2015. "Guidelines for
                        Normalising Early Modern English Corpora: Decisions and
                        Justifications."
                    <cite class="title italic">ICAME Journal</cite> 39: 5–24. <a class="ref" href="http://doi.org/10.1515/icame-2015-0001" onclick="window.open('http://doi.org/10.1515/icame-2015-0001'); return false">doi:10.1515/icame-2015-0001</a>.</div><div class="bibl"><span class="ref" id="baron2009"><!-- close -->Baron et al. 2009</span> Baron, Alistair, Paul Rayson, and
                    Dawn Archer. 2009. "Automatic Standardization of Spelling
                        for Historical Text Mining." University of Maryland.</div><div class="bibl"><span class="ref" id="bergkirkpatrick2014"><!-- close -->Berg-Kirkpatrick and Klein 2014</span> Berg-Kirkpatrick, Taylor, and Dan Klein. 2014. "Improved
                        Typesetting Models for Historical OCR." In <cite class="title italic">Proceedings of the 52nd Annual Meeting of the Association for Computational
                        Linguistics (Volume 2: Short Papers)</cite>, 118–23. Baltimore, Maryland:
                    Association for Computational Linguistics. <a class="ref" href="http://www.aclweb.org/anthology/P14-2020" onclick="window.open('http://www.aclweb.org/anthology/P14-2020'); return false">http://www.aclweb.org/anthology/P14-2020</a>.</div><div class="bibl"><span class="ref" id="bergkirkpatrick2013"><!-- close -->Berg-Kirkpatrick et al. 2013</span> Berg-Kirkpatrick, Taylor, Greg Durrett, and Dan Klein. 2013. "Unsupervised Transcription of Historical Documents." In
                        <cite class="title italic">Proceedings of the 51st Annual Meeting of the
                        Association for Computational Linguistics</cite> (Volume 1: Long Papers),
                    207–17. Sofia, Bulgaria: Association for Computational Linguistics. <a class="ref" href="http://www.aclweb.org/anthology/P13-1021" onclick="window.open('http://www.aclweb.org/anthology/P13-1021'); return false">http://www.aclweb.org/anthology/P13-1021</a>.</div><div class="bibl"><span class="ref" id="biber2009"><!-- close -->Biber and Conrad 2009</span> Biber, Douglas, and Susan
                    Conrad. 2009. <cite class="title italic">Register, Genre, and Style</cite>. Cambridge
                    University Press.</div><div class="bibl"><span class="ref" id="bollmann2011"><!-- close -->Bollmann et al. 2011</span> Bollmann, Marcel, Florian
                    Petran, and Stefanie Dipper. 2011. "Applying Rule-Based
                        Normalization to Different Types of Historical Texts – an
                        Evaluation." In <cite class="title italic">Human language technology
                        challenges for computer science and linguistics</cite>, 166–77.
                    Springer.</div><div class="bibl"><span class="ref" id="breuel2013"><!-- close -->Breuel et al. 2013</span> Breuel, Thomas M, Adnan
                    Ul-Hasan, Mayce Ali Al-Azawi, and Faisal Shafait. 2013. "High-Performance OCR for Printed English and Fraktur Using LSTM
                        Networks." In <cite class="title italic">2th International Conference on
                        Document Analysis and Recognition (ICDAR), 2013</cite>, 683–87.
                    IEEE.</div><div class="bibl"><span class="ref" id="doermann2014"><!-- close -->Doermann et al. 2014</span> Doermann, David Scott, and
                    Karl Tombre, eds. 2014. <cite class="title italic">Handbook of Document Image
                        Processing and Recognition</cite>. Springer.</div><div class="bibl"><span class="ref" id="dudczak2014"><!-- close -->Dudczak et al. 2014</span> Dudczak, Adam, Aleksandra
                    Nowak, and Tomasz Parkoła. 2014. "Creation of Custom
                        Recognition Profiles for Historical Documents." In <cite class="title italic">Proceedings of the First International Conference on Digital
                        Access to Textual Cultural Heritage</cite>, 143–46. ACM.</div><div class="bibl"><span class="ref" id="eisenstein1979"><!-- close -->Eisenstein 1979</span> Eisenstein, Elisabeth. 1979.
                        <cite class="title italic">The Printing Press as an Agent of Change and the
                        Structure of Communications Revolutions</cite>. New York: Cambridge
                    University Press.</div><div class="bibl"><span class="ref" id="ernstgerlach2006"><!-- close -->Ernst-Gerlach and Fuhr 2006</span> Ernst-Gerlach,
                    Andrea, and Norbert Fuhr. 2006. "Generating Search Term
                        Variants for Text Collections with Historic Spellings." In <cite class="title italic">European Conference on Information Retrieval</cite>, 49–60.
                    Springer.</div><div class="bibl"><span class="ref" id="ernstgerlach2007"><!-- close -->Ernst-Gerlach and Fuhr 2007</span> Ernst-Gerlach,
                    Andrea, and Norbert Fuhr. 2007. "Retrieval in Text
                        Collections with Historic Spelling Using Linguistic and Spelling
                        Variants." In <cite class="title italic">Proceedings of the 7th ACM/IEEE-CS
                        Joint Conference on Digital Libraries</cite>, 333–41. ACM.</div><div class="bibl"><span class="ref" id="fischer2009"><!-- close -->Fischer et al. 2009</span> Fischer, Andreas, Markus
                    Wüthrich, Marcus Liwicki, Volkmar Frinken, Horst Bunke, Gabriel Viehhauser, and
                    Michael Stolz. 2009. "Automatic Transcription of Handwritten
                        Medieval Documents." In <cite class="title italic">15th International
                        Conference on Virtual Systems and Multimedia, 2009 (VSMM’09)</cite>,
                    137–42. IEEE.</div><div class="bibl"><span class="ref" id="geyken2015"><!-- close -->Geyken and Gloning 2015</span> Geyken, Alexander, and
                    Thomas Gloning. 2015. "A Living Text Archive of 15th to 19th
                        Century German. Corpus Strategies, Technologies, Organization." In
                        <cite class="title italic">Historical Corpora</cite>, edited by Jost Gippert and
                    Ralf Gehrke, 165–79. Tübingen: Narr Verlag.</div><div class="bibl"><span class="ref" id="gippert2015"><!-- close -->Gippert and Gehrke 2015</span> Gippert, Jost, and Ralf
                    Gehrke, eds. 2015. <cite class="title italic">Historical Corpora. Challenges and
                        Perspectives</cite>. Tübingen: Narr Verlag.</div><div class="bibl"><span class="ref" id="gloning2007"><!-- close -->Gloning 2007</span> Gloning, Thomas. 2007. "<span class="foreign i">Deutsche Kräuterbücher des 12. bis 18.
                            Jahrhunderts. Textorganisation, Wortgebrauch, funktionale
                            Syntax.</span>" In <cite class="title italic"><span class="foreign i">Gesund und krank im Mittelalter. Marburger Beiträge zur
                            Kulturgeschichte der Medizin</span></cite>, edited by Andreas Meyer
                    and Jürgen Schulz-Grobert, 9–88. Leipzig: Eudora-Verlag.</div><div class="bibl"><span class="ref" id="gotscharek2011"><!-- close -->Gotscharek et al. 2011</span> Gotscharek, Annette,
                    Ulrich Reffle, Christoph Ringlstetter, Klaus U Schulz, and Andreas Neumann.
                    2011. "Towards information retrieval on historical document
                        collections: the role of matching procedures and special lexica."
                    <cite class="title italic">International Journal on Document Analysis and Recognition
                        (IJDAR)</cite> 14 (2). Springer: 159–71.</div><div class="bibl"><span class="ref" id="graves2009"><!-- close -->Graves et al. 2009</span> Graves, Alex, Marcus Liwicki,
                    Santiago Fernández, Roman Bertolami, Horst Bunke, and Jürgen Schmidhuber. 2009.
                        "A Novel Connectionist System for Unconstrained
                        Handwriting Recognition."
                    <cite class="title italic">IEEE Transactions on Pattern Analysis and Machine
                        Intelligence</cite> 31 (5). IEEE: 855–68.</div><div class="bibl"><span class="ref" id="habermann2003"><!-- close -->Habermann 2003</span> Habermann, Mechthild. 2003.
                        "<span class="foreign i">Der Sprachenwechsel und seine
                            Folgen: Zur Wissensvermittlung in lateinischen und deutschen
                            Kräuterbüchern des 16. Jahrhunderts.</span>"
                    <cite class="title italic"><span class="foreign i">Sprachwissenschaft</span></cite>
                    28 (3). Winter: 325–54.</div><div class="bibl"><span class="ref" id="hochreiter1997"><!-- close -->Hochreiter and Schmidhuber 1997</span> Hochreiter,
                    Sepp, and Jürgen Schmidhuber. 1997. "Long Short-Term
                        Memory."
                    <cite class="title italic">Neural computation</cite> 9 (8). MIT Press:
                    1735–80.</div><div class="bibl"><span class="ref" id="jurish2013"><!-- close -->Jurish 2013</span> Jurish, Bryan. 2013. "Canonicalizing the Deutsches Textarchiv." In <cite class="title italic">Proceedings of <span class="foreign i">Perspektiven einer
                            corpusbasierten historischen Linguistik und Philologie</span>
                        (Berlin, 12th - 13th December 2011)</cite>, edited by Ingelore Hafemann.
                    Vol. 4. Thesaurus Linguae Aegyptiae. Berlin, Germany: <span class="foreign i">Berlin-Brandenburgische Akademie der Wissenschaften</span>. <a class="ref" href="http://edoc.bbaw.de/frontdoor.php?source_opus=2443" onclick="window.open('http://edoc.bbaw.de/frontdoor.php?source_opus=2443'); return false">http://edoc.bbaw.de/frontdoor.php?source_opus=2443</a>.</div><div class="bibl"><span class="ref" id="kirchner2016"><!-- close -->Kirchner et al. 2016</span> Kirchner, Felix, Marco
                    Dittrich, Philipp Beckenbauer, and Maximilian Nöth. 2016. "OCR bei Inkunabeln – Offizinspezifischer Ansatz der UB Würzburg."
                    <cite class="title italic">ABI Technik</cite> 36 (3): 178–88. </div><div class="bibl"><span class="ref" id="klein1999"><!-- close -->Klein 1999</span> Klein, Wolf Peter. 1999. <cite class="title italic"><span class="foreign i">Die Geschichte der meteorologischen
                            Kommunikation in Deutschland. Eine historische Fallstudie zur
                            Entwicklung von Wissenschaftssprachen</span></cite>. Hildesheim,
                    Zürich, New York: Olms.</div><div class="bibl"><span class="ref" id="klein2011"><!-- close -->Klein 2011</span> Klein, Wolf Peter. 2011. "<span class="foreign i">Die deutsche Sprache in der
                            Gelehrsamkeit der frühen Neuzeit. Von der lingua barbarica zur
                            HaubtSprache.</span>" In <cite class="title italic"><span class="foreign i">Diskurse der Gelehrtenkultur in der Frühen Neuzeit. Ein
                            Handbuch</span></cite>, edited by Herbert Jaumann, 465–516. de
                    Gruyter.</div><div class="bibl"><span class="ref" id="krause2016"><!-- close -->Krause and Zeldes 2016</span> Krause, Thomas, and Amir
                    Zeldes. 2016. "ANNIS3: A New Architecture for Generic Corpus
                        Query and Visualization."
                    <cite class="title italic">Digital Scholarship in the Humanities</cite> 31 (1).
                    Oxford University Press: 118–39.</div><div class="bibl"><span class="ref" id="ludeling2008"><!-- close -->Lüdeling and Zeldes 2008</span> Lüdeling, Anke, and
                    Amir Zeldes. 2008. "Three Views on Corpora: Corpus
                        Linguistics, Literary Computing, and Computational Linguistics."
                    <cite class="title italic"><span class="foreign i">Jahrbuch für
                            Computerphilologie</span></cite> 9: 149–78.</div><div class="bibl"><span class="ref" id="ludeling2004"><!-- close -->Lüdeling et al. 2004</span> Lüdeling, Anke, Thorwald
                    Poschenrieder, and Lukas Faulstich. 2004. "<span class="foreign i">DeutschDiachronDigital - Ein diachrones Korpus des
                            Deutschen.</span>"
                    <cite class="title italic"><span class="foreign i">Jahrbuch für
                            Computerphilologie</span></cite> 6: 119–36.</div><div class="bibl"><span class="ref" id="nartker2005"><!-- close -->Nartker et al. 2005</span> Nartker, Thomas A., Stephen
                    V. Rice, and Steven E. Lumos. 2005. "Software Tools and Test
                        Data for Research and Testing of Page-Reading OCR Systems." In <cite class="title italic">Electronic Imaging 2005</cite>, 37–47. International Society
                    for Optics; Photonics.</div><div class="bibl"><span class="ref" id="odebrecht2017"><!-- close -->Odebrecht et al. 2017</span> Odebrecht, Carolin, Malte
                    Belz, Vivian Voigt, Amir Zeldes, Anke Lüdeling, and Thomas Krause. 2017, in
                    press. "RIDGES Herbology - Designing a Diachronic
                        Multi-Layer Corpus."
                    <cite class="title italic">Language Resources and Evolution</cite>.</div><div class="bibl"><span class="ref" id="pilz2008"><!-- close -->Pilz et al. 2008</span> Pilz, Thomas, Andrea Ernst-Gerlach,
                    Sebastian Kempken, Paul Rayson, and Dawn Archer. 2008. "The
                        Identification of Spelling Variants in English and German Historical Texts:
                        Manual or Automatic?"
                    <cite class="title italic">Literary and Linguistic Computing</cite> 23 (1). ALLC:
                    65–72.</div><div class="bibl"><span class="ref" id="piotrowski2012"><!-- close -->Piotrowski 2012</span> Piotrowski, Michael. 2012.
                        <cite class="title italic">Natural Language Processing for Historical
                        Texts</cite>. Morgan &amp; Claypool Publishers.</div><div class="bibl"><span class="ref" id="reddy2006"><!-- close -->Reddy and Crane 2006</span> Reddy, Sravana, and Gregory
                    Crane. 2006. "A Document Recognition System for Early Modern
                        Latin." In <cite class="title italic">Chicago Colloquium on Digital
                        Humanities and Computer Science: What Do You Do with a Million Books,
                        Chicago, IL</cite>. Vol. 23.</div><div class="bibl"><span class="ref" id="reul2017a"><!-- close -->Reul et al. 2017a</span> Reul, Christian, Marco Dittrich,
                    and Martin Gruner. 2017. "Case Study of a highly automated
                        Layout Analysis and OCR of an incunabulum: '<span class="foreign i">Der Heiligen Leben</span>' (1488)."
                    <cite class="title italic">ArXiv e-prints</cite>. <a class="ref" href="https://arxiv.org/abs/1701.07395" onclick="window.open('https://arxiv.org/abs/1701.07395'); return false">https://arxiv.org/abs/1701.07395</a>.</div><div class="bibl"><span class="ref" id="reul2017b"><!-- close -->Reul et al. 2017b</span> Reul, Christian, Uwe Springmann,
                    and Frank Puppe. 2017. "LAREX – A semi-automatic open-source
                        Tool for Layout Analysis and Region Extraction on Early Printed
                        Books."
                    <cite class="title italic">ArXiv e-prints.</cite>
                    <a class="ref" href="https://arxiv.org/abs/1701.07396" onclick="window.open('https://arxiv.org/abs/1701.07396'); return false">https://arxiv.org/abs/1701.07396</a>.</div><div class="bibl"><span class="ref" id="riecke2004"><!-- close -->Riecke 2004</span> Riecke, Jörg. 2004. <cite class="title italic"><span class="foreign i">Die Frühgeschichte der
                            mittelalterlichen medizinischen Fachsprache im
                        Deutschen</span></cite>. Vol. 2 <span class="foreign i">Bände, Band 1:
                        Untersuchungen, Band 2: Wörterbuch.</span> Berlin: Walter de
                    Gruyter.</div><div class="bibl"><span class="ref" id="rissanen1989"><!-- close -->Rissanen 1989</span> Rissanen, Matti. 1989. "Three Problems Connected with the Use of Diachronic
                        Corpora."
                    <cite class="title italic">ICAME</cite> 13: 16–19.</div><div class="bibl"><span class="ref" id="rissanen2008"><!-- close -->Rissanen 2008</span> Rissanen, Matti. 2008. "Corpus Linguistics and Historical Linguistics." In
                        <cite class="title italic">Corpus Linguistics. an International Handbook</cite>,
                    edited by Anke Lüdeling and Merja Kytö, 1:53–68. Berlin: Mouton de
                    Gruyter.</div><div class="bibl"><span class="ref" id="rydbergcox2009"><!-- close -->Rydberg-Cox 2009</span> Rydberg-Cox, Jeffrey A. 2009.
                        "Digitizing Latin Incunabula: Challenges, Methods, and
                        Possibilities."
                    <cite class="title italic">Digital Humanities Quarterly</cite> 3 (1). <a class="ref" href="http://www.digitalhumanities.org/dhq/vol/3/1/000027/000027.html" onclick="window.open('http://www.digitalhumanities.org/dhq/vol/3/1/000027/000027.html'); return false">http://www.digitalhumanities.org/dhq/vol/3/1/000027/000027.html</a></div><div class="bibl"><span class="ref" id="springmann2015"><!-- close -->Springmann 2015</span> Springmann, Uwe. 2015. "Ocrocis: A high accuracy OCR method to convert early printings
                        into digital text – a tutorial."
                    <a class="ref" href="http://cistern.cis.lmu.de/ocrocis/tutorial.pdf" onclick="window.open('http://cistern.cis.lmu.de/ocrocis/tutorial.pdf'); return false">http://cistern.cis.lmu.de/ocrocis/tutorial.pdf</a>.</div><div class="bibl"><span class="ref" id="springmann2016a"><!-- close -->Springmann and Fink 2016</span> Springmann, Uwe, and
                    Florian Fink. 2016. "CIS OCR Workshop v1.0: OCR and
                        postcorrection of early printings for digital humanities."
                    <a class="ref" href="http://doi.org/10.5281/zenodo.46571" onclick="window.open('http://doi.org/10.5281/zenodo.46571'); return false">doi:10.5281/zenodo.46571</a>.</div><div class="bibl"><span class="ref" id="springmann2014"><!-- close -->Springmann et al. 2014</span> Springmann, Uwe,
                    Dietmar Najock, Hermann Morgenroth, Helmut Schmid, Annette Gotscharek, and
                    Florian Fink. 2014. "OCR of historical printings of Latin
                        texts: problems, prospects, progress." In <cite class="title italic">Proceedings of the First International Conference on Digital Access to
                        Textual Cultural Heritage</cite>, 57–61. DATeCH ’14. New York, NY, USA:
                    ACM. <a class="ref" href="http://doi.org/10.1145/2595188.2595197" onclick="window.open('http://doi.org/10.1145/2595188.2595197'); return false">doi:10.1145/2595188.2595197</a>.</div><div class="bibl"><span class="ref" id="springmann2016b"><!-- close -->Springmann et al. 2016</span> Springmann, Uwe,
                    Florian Fink, and Klaus-U. Schulz. 2016. "Automatic quality
                        evaluation and (semi-) automatic improvement of mixed models for OCR on
                        historical documents."
                    <a class="ref" href="http://arxiv.org/abs/1606.05157" onclick="window.open('http://arxiv.org/abs/1606.05157'); return false">http://arxiv.org/abs/1606.05157</a>.</div><div class="bibl"><span class="ref" id="strange2014"><!-- close -->Strange et al. 2014</span> Strange, Carolyn, Daniel
                    McNamara, Josh Wodak, and Ian Wood. 2014. "Mining for the
                        Meanings of a Murder: The Impact of OCR Quality on the Use of Digitized
                        Historical Newspapers."
                    <cite class="title italic">Digital Humanities Quarterly</cite> 8 (1). <a class="ref" href="http://www.digitalhumanities.org/dhq/vol/8/1/000168/000168.html" onclick="window.open('http://www.digitalhumanities.org/dhq/vol/8/1/000168/000168.html'); return false">http://www.digitalhumanities.org/dhq/vol/8/1/000168/000168.html</a>.</div><div class="bibl"><span class="ref" id="tanner2009"><!-- close -->Tanner et al. 2009</span> Tanner, Simon, Trevor Muñoz,
                    and Pich Hemy Ros. 2009. "Measuring Mass Text Digitization
                        Quality and Usefulness."
                    <cite class="title italic">D-Lib Magazine</cite> 15 (7/8): 1082–9873. <a class="ref" href="http://www.dlib.org/dlib/july09/munoz/07munoz.html" onclick="window.open('http://www.dlib.org/dlib/july09/munoz/07munoz.html'); return false">http://www.dlib.org/dlib/july09/munoz/07munoz.html</a></div><div class="bibl"><span class="ref" id="traub2015"><!-- close -->Traub et al. 2015</span> Traub, Myriam C, Jacco van
                    Ossenbruggen, and Lynda Hardman. 2015. "Impact Analysis of
                        Ocr Quality on Research Tasks in Digital Archives." In <cite class="title italic">International Conference on Theory and Practice of Digital
                        Libraries</cite>, 252–63. Springer.</div><div class="bibl"><span class="ref" id="ulhasan2016"><!-- close -->Ul-Hasan et al. 2016</span> Ul-Hasan, Adnan, Syed Saqib
                    Bukhari, and Andreas Dengel. 2016. "OCRoRACT: A Sequence
                        Learning OCR System Trained on Isolated Characters." In <cite class="title italic">12th IAPR Workshop on Document Analysis Systems (DAS)</cite>,
                    174–79. IEEE.</div><div class="bibl"><span class="ref" id="vobl2014"><!-- close -->Vobl et al. 2014</span> Vobl, Thorsten, Annette Gotscharek,
                    Uli Reffle, Christoph Ringlstetter, and Klaus U. Schulz. 2014. "PoCoTo - an open source system for efficient interactive
                        postcorrection of OCRed historical texts." In <cite class="title italic">Proceedings of the First International Conference on Digital Access to
                        Textual Cultural Heritage</cite>, 57–61. DATeCH ’14. New York, NY, USA:
                    ACM. <a class="ref" href="http://doi.org/10.1145/2595188.2595197" onclick="window.open('http://doi.org/10.1145/2595188.2595197'); return false">doi:10.1145/2595188.2595197</a>.</div><div class="bibl"><span class="ref" id="weiß2016"><!-- close -->Weiß and Schnelle 2016</span> Weiß, Zarah, and Gohar
                    Schnelle. 2016. "Sentence Annotation Guidelines for Early
                        New High German." Universität Tübingen; Humboldt-Universität zu
                    Berlin (submitted). <a class="ref" href="http://sfs.uni-tuebingen.de/langbank/src/enhg_sent_segm-english-v4.pdf" onclick="window.open('http://sfs.uni-tuebingen.de/langbank/src/enhg_sent_segm-english-v4.pdf'); return false">http://sfs.uni-tuebingen.de/langbank/src/enhg_sent_segm-english-v4.pdf</a>.</div><div class="bibl"><span class="ref" id="weel2011"><!-- close -->van der Weel 2011</span> Weel, Adriaan van der. 2011.
                        <cite class="title italic">Changing Our Textual Minds. Towards a Digital Order of
                        Knowledge</cite>. Manchester: Manchester University Press.</div></div><div class="toolbar"><a href="/dhq/vol/11/2/index.html">2017 11.2</a>
             | 
            <a rel="external" href="/dhq/vol/11/2/000288.xml">XML</a>
            | 
            <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div></div><script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dhquarterly'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script><div id="comments"><div id="disqus_thread"/><script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dhquarterly'; // required: replace example with your forum shortname

    // The following are highly recommended additional parameters. Remove the slashes in front to use.
    var disqus_identifier = '000288';
    var disqus_url = 'http://www.digitalhumanities.org/dhq/vol/11/2/000288/000288.html';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><div id="footer"> 
            URL: http://www.digitalhumanities.org/dhq/vol/11/2/000288/000288.html<br/>Last updated:
            <script type="text/javascript">
                var monthArray = new initArray("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December");
                var lastModifiedDate = new Date(document.lastModified);
                var currentDate = new Date();
                document.write(" ",monthArray[(lastModifiedDate.getMonth()+1)]," ");
                document.write(lastModifiedDate.getDate(),", ",(lastModifiedDate.getFullYear()));
            </script><br/> Comments: <a href="mailto:dhqinfo@digitalhumanities.org" class="footer">dhqinfo@digitalhumanities.org</a><br/> Published by:
            <a href="http://www.digitalhumanities.org" class="footer">The Alliance of Digital Humanities Organizations</a><br/>Affiliated with: <a href="http://llc.oxfordjournals.org/">Literary and Linguistic Computing</a><br/> Copyright 2005 - <script type="text/javascript">
                document.write(currentDate.getFullYear());</script><br/><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png"/></a><br/>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
        </div></div></div></body></html>