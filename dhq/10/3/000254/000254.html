<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><title>DHQ: Digital Humanities Quarterly: Towards a Rationale of Audio-Text</title><link rel="stylesheet" type="text/css" href="/dhq/common/css/dhq.css"/><link rel="stylesheet" type="text/css" media="screen" href="/dhq/common/css/dhq_screen.css"/><link rel="stylesheet" type="text/css" media="print" href="/dhq/common/css/dhq_print.css"/><link rel="alternate" type="application/atom+xml" href="/dhq/feed/news.xml"/><link rel="shortcut icon" href="/dhq/common/images/favicon.ico"/><script type="text/javascript" src="/dhq/common/js/javascriptLibrary.js">
                &lt;!-- Javascript functions --&gt;
            </script><script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-15812721-1']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
s.parentNode.insertBefore(ga, s);
 })();

        </script></head><body><div id="top"><div id="backgroundpic"><script type="text/javascript" src="/dhq/common/js/pics.js"><!--displays banner image--></script></div><div id="banner"><div id="dhqlogo"><img src="/dhq/common/images/dhqlogo.png" alt="DHQ Logo"/></div><div id="longdhqlogo"><img src="/dhq/common/images/dhqlogolonger.png" alt="Digital Humanities Quarterly Logo"/></div></div><div id="topNavigation"><div id="topnavlinks"><span><a href="/dhq/" class="topnav">home</a></span><span><a href="/dhq/submissions/index.html" class="topnav">submissions</a></span><span><a href="/dhq/about/about.html" class="topnav">about dhq</a></span><span><a href="/dhq/people/people.html" class="topnav">dhq people</a></span><span id="rightmost"><a href="/dhq/contact/contact.html" class="topnav">contact</a></span></div><div id="search"><form action="/dhq/findIt" method="get" onsubmit="javascript:document.location.href=cleanSearch(this.queryString.value); return false;"><div><input type="text" name="queryString" size="18"/> <input type="submit" value="Search"/></div></form></div></div></div><div id="main"><div id="leftsidebar"><div id="leftsidenav"><span>Current Issue<br/></span><ul><li><a href="/dhq/vol/11/3/index.html">2017: 11.3</a></li></ul><span>Preview Issue<br/></span><ul><li><a href="/dhq/preview/index.html">2017: 11.4</a></li></ul><span>Previous Issues<br/></span><ul><li><a href="/dhq/vol/11/2/index.html">2017: 11.2</a></li><li><a href="/dhq/vol/11/1/index.html">2017: 11.1</a></li><li><a href="/dhq/vol/10/4/index.html">2016: 10.4</a></li><li><a href="/dhq/vol/10/3/index.html">2016: 10.3</a></li><li><a href="/dhq/vol/10/2/index.html">2016: 10.2</a></li><li><a href="/dhq/vol/10/1/index.html">2016: 10.1</a></li><li><a href="/dhq/vol/9/4/index.html">2015: 9.4</a></li><li><a href="/dhq/vol/9/3/index.html">2015: 9.3</a></li><li><a href="/dhq/vol/9/2/index.html">2015: 9.2</a></li><li><a href="/dhq/vol/9/1/index.html">2015: 9.1</a></li><li><a href="/dhq/vol/8/4/index.html">2014: 8.4</a></li><li><a href="/dhq/vol/8/3/index.html">2014: 8.3</a></li><li><a href="/dhq/vol/8/2/index.html">2014: 8.2</a></li><li><a href="/dhq/vol/8/1/index.html">2014: 8.1</a></li><li><a href="/dhq/vol/7/3/index.html">2013: 7.3</a></li><li><a href="/dhq/vol/7/2/index.html">2013: 7.2</a></li><li><a href="/dhq/vol/7/1/index.html">2013: 7.1</a></li><li><a href="/dhq/vol/6/3/index.html">2012: 6.3</a></li><li><a href="/dhq/vol/6/2/index.html">2012: 6.2</a></li><li><a href="/dhq/vol/6/1/index.html">2012: 6.1</a></li><li><a href="/dhq/vol/5/3/index.html">2011: 5.3</a></li><li><a href="/dhq/vol/5/2/index.html">2011: 5.2</a></li><li><a href="/dhq/vol/5/1/index.html">2011: 5.1</a></li><li><a href="/dhq/vol/4/2/index.html">2010: 4.2</a></li><li><a href="/dhq/vol/4/1/index.html">2010: 4.1</a></li><li><a href="/dhq/vol/3/4/index.html">2009: 3.4</a></li><li><a href="/dhq/vol/3/3/index.html">2009: 3.3</a></li><li><a href="/dhq/vol/3/2/index.html">2009: 3.2</a></li><li><a href="/dhq/vol/3/1/index.html">2009: 3.1</a></li><li><a href="/dhq/vol/2/1/index.html">2008: 2.1</a></li><li><a href="/dhq/vol/1/2/index.html">2007: 1.2</a></li><li><a href="/dhq/vol/1/1/index.html">2007: 1.1</a></li></ul><span>Indexes<br/></span><ul><li><a href="/dhq/index/title.html"> Title</a></li><li><a href="/dhq/index/author.html"> Author</a></li></ul></div><img src="/dhq/common/images/lbarrev.png" style="margin-left : 7px;" alt="sidenavbarimg"/><div id="leftsideID"><b>ISSN 1938-4122</b><br/></div><div class="leftsidecontent"><h3>Announcements</h3><ul><li><a href="/dhq/announcements/index.html#reviewers">Call for Reviewers</a></li><li><a href="/dhq/announcements/index.html#submissions">Call for Submissions</a></li></ul></div><div class="leftsidecontent"><script type="text/javascript">addthis_pub  = 'dhq';</script><a href="http://www.addthis.com/bookmark.php" onmouseover="return addthis_open(this, '', '[URL]', '[TITLE]')" onmouseout="addthis_close()" onclick="return addthis_sendto()"><img src="http://s9.addthis.com/button1-addthis.gif" width="125" height="16" alt="button1-addthis.gif"/></a><script type="text/javascript" src="http://s7.addthis.com/js/152/addthis_widget.js">&lt;!-- Javascript functions --&gt;</script></div></div><div id="mainContent"><div id="printSiteTitle">DHQ: Digital Humanities Quarterly</div><div xmlns:dhqBiblio="http://digitalhumanities.org/dhq/ns/biblio" class="DHQarticle"><div id="pubInfo">2016<br/>Volume 10 Number 2</div><div class="toolbar"><form id="taporware" action="get"><div><a href="/dhq/vol/10/3/index.html">2016 10.3</a>
                     | 
                    <a rel="external" href="/dhq/vol/10/3/000254.xml">XML</a>

| 
		   Discuss
			(<a href="/dhq/vol/10/3/000254/000254.html#disqus_thread" data-disqus-identifier="000254">
				Comments
			</a>)
                </div></form></div>
    <div class="DHQheader">
        
            
                
                <h1 class="articleTitle lang en">Towards a Rationale of Audio-Text</h1>
                <div class="author"><a rel="external" href="../bios.html#clement_tanya_e.">Tanya E. Clement</a> &lt;<a href="mailto:tclement_at_ischool_dot_utexas_dot_edu" onclick="javascript:window.location.href='mailto:'+deobfuscate('tclement_at_ischool_dot_utexas_dot_edu'); return false;" onkeypress="javascript:window.location.href='mailto:'+deobfuscate('tclement_at_ischool_dot_utexas_dot_edu'); return false;">tclement_at_ischool_dot_utexas_dot_edu</a>&gt;, University of Texas at Austin</div>
            
            

            
        
        
        
        
    <span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft.genre=article&amp;rft.atitle=Towards%20a%20Rationale%20of%20Audio-Text&amp;rft.jtitle=Digital%20Humanities%20Quarterly&amp;rft.stitle=DHQ&amp;rft.issn=1938-4122&amp;rft.date=2016-07-12&amp;rft.volume=010&amp;rft.issue=2&amp;rft.aulast=Clement&amp;rft.aufirst=Tanya E.&amp;rft.au=Tanya E.%20Clement"> </span></div>

    <div id="DHQtext">
        
            <div id="abstract"><h2>Abstract</h2>
                
                <p>Digital humanities scholars have made a tradition of problematizing our
                    understanding of textuality through discussions concerning the design of
                    information systems for texts that, in many cases, still look like books. This
                    discussion is concerned with how creating opportunities for studying audio texts
                    further complicates our understanding of "the rationale of a
                        textualized document," defined by Jerome McGann as "the dynamic structure of a document as it is realized in
                        determinate (artisanal) and determinable (reflective) ways". This
                    discussion frames a rationale of audio text within the context of developing
                    information infrastructures for accessing audio texts. I introduce a tool called
                    ARLO that we have been developing in the High Performance Sound Technologies for
                    Access and Scholarship (HiPSTAS) project (<a class="ref" href="http://www.hipstas.org" onclick="window.open('http://www.hipstas.org'); return false">http://www.hipstas.org</a>) for accessing and analyzing sound collections
                    alongside new standards being proposed for the development of audio visual (AV)
                    metadata and content models. The discussion concludes by considering what these
                    interventions tell us about how a rationale of audio textuality helps us rethink
                    rationales of text in digital environments.</p>
            </div>
            
        
        
            <div class="div div0">
                <h1 class="head">1. Introduction</h1>
                <div class="counter"><a href="#p1">1</a></div><div class="ptext" id="p1">In the 1980s and 1990s, <cite class="title italic">A Critique of Modern Textual
                        Criticism</cite>, <cite class="title italic">The Textual Condition</cite>, and
                        <cite class="title italic">Bibliography and the Sociology of Texts</cite> laid
                    theoretical groundwork for understanding the social nature of text [<a class="ref" href="#mcgann1983">McGann 1983</a>]
                    [<a class="ref" href="#mcgann1991">McGann 1991</a>]
                    [<a class="ref" href="#mckenzie1999">McKenzie 1999</a>]. Namely, McGann and McKenzie argued against the
                    traditional editing practices that included identifying a <em class="term">definitive
                        text</em>, a <em class="term">copy text</em>, an <em class="term">ideal text</em>, an
                        <em class="term">Ur text</em>, or a <em class="term">standard text</em> for scholarly
                    editions. They reasoned that these practices obfuscated the social histories and
                    contexts that meaning-making with texts must reflect, including how texts are
                    produced, transmitted, received, and consumed. McCann, McKenzie, and others
                    emphasized textual theories that reflected the significance of materiality,
                    versioning, technical transmission, and institutional contexts. McGann’s "The Rationale of Hypertext" applies these social text
                    theories in the digital realm [<a class="ref" href="#mcgann1995">McGann 1995</a>] where an escape from
                        "book-bound" and "fixed point" navigations indicates a new kind of
                    social condition in the digital age of hypertexts. In the fifteen years since,
                    we have seen multiple scholars (such as [<a class="ref" href="#bryant2002">Bryant 2002</a>]
                    [<a class="ref" href="#drucker2002">Drucker 2002</a>]
                    [<a class="ref" href="#liu2004">Liu 2004</a>]
                    [<a class="ref" href="#kirschenbaum2008">Kirschenbaum 2008</a>]) take up McGann’s charge to use social text
                    theory and the seemingly expanded perspective afforded by the digital
                    environment to rethink what McGann has called "the rationale
                        of a textualized document"
                    [<a class="ref" href="#mcgann2001">McGann 2001</a>, 137]. Of this tradition, this discussion is
                    concerned with how digital audio texts further shape rationales of texts more
                        generally.<a class="noteRef" href="#d938e264">[1]</a>
                </div>
                <div class="counter"><a href="#p2">2</a></div><div class="ptext" id="p2">First, after defining some key terms, I frame this problem within conversations
                    about textuality that have arisen around developing information infrastructures
                    for accessing <em class="term">verbal texts</em>. What I am calling verbal texts are
                    documents such as books, articles, letters, and audio for which the content has
                    been represented in information systems as linguistic content or words. Second,
                    in order to situate rationales of verbal texts in the context of audio-texts, I
                    describe a specific example – the development of a tool for accessing and
                    analyzing sound collections in the High Performance Sound Technologies for
                    Access and Scholarship (HiPSTAS) project (<a class="ref" href="http://www.hipstas.org" onclick="window.open('http://www.hipstas.org'); return false">http://www.hipstas.org</a>). Third, I use this history and this specific
                    example to consider how current content models and metadata standards reflect
                    rationales of audio texts both in digital humanities and beyond. Finally, I
                    conclude by considering what these interventions tell us about how we may
                    rethink a rationale of textuality in digital environments.</div>
            </div>
            <div class="div div0">
                <h1 class="head">2. Rationales of Text</h1>
                <div class="counter"><a href="#p3">3</a></div><div class="ptext" id="p3">The <em class="term">rationale</em> of a text comprises the principles by which we argue
                    that text makes meaning. This discussion is guided by McGann’s definition of
                    text’s <em class="term">rationale</em> as part of a social condition which he contends is
                    made apparent through "the dynamic structure of a document
                        as it is realized in determinate (artisanal) and determinable (reflective)
                        ways"
                    [<a class="ref" href="#mcgann2001">McGann 2001</a>, 137]. With this definition, McGann is focused
                    primarily on verbal texts, but he is also considering how the physical object of
                    the text is made as artisanal properties. These properties might include how a
                    book is bound or which picture might be on the cover of a particular edition or
                    which font or words were chosen. The text's reflective properties, on the other
                    hand, point to how this physical and conceptual text is understood by a reader
                    who might make meaning about (or reflect on) that book binding, that image, and
                    that font or word choice. These two kinds of information, which McGann calls
                    determinate and determinable, jointly or dynamically comprise the verbal text’s
                    meaning in social text theory.</div>
                <div class="counter"><a href="#p4">4</a></div><div class="ptext" id="p4">Additionally, by placing special emphasis on how interpretation relies on the
                    realization of a <em class="term">document,</em> McGann situates these determinate and
                    determinable properties within the context of processes for textual production,
                    transmission, and reception in social text theory. Unlike the concept of
                        <em class="term">text</em>, which can span multiple iterations of a work,
                        <em class="term">document</em> is understood as a situated object in time and place:
                    it is "any physical or symbolic sign, preserved or recorded,
                        intended to represent, to reconstruct, or to demonstrate a physical or
                        conceptual phenomenon" (Briet, 1951 quoted in [<a class="ref" href="#buckland1997">Buckland 1997</a>]). Much as social text theory is concerned with the
                    publishing and social systems (the scholarly infrastructure) that define
                    textuality, document theory in information science likewise comprises the study
                    of the <em class="term">document</em> within particular contexts or systems of
                    organization and distribution called <em class="term">documentation</em> including
                    collecting, standardizing, filing, classifying, copying, disseminating, and
                    preserving documents [<a class="ref" href="#buckland1997">Buckland 1997</a>, 805]. Historically,
                    these concerns have been shared by many information scholars who consider the
                        <em class="term">document</em> in terms of these analog, digital, and decidedly
                    social, processes of documentation (for examples, see [<a class="ref" href="#otlet1990">Otlet 1990</a>]; [<a class="ref" href="#frohmann2004">Frohmann 2004</a>]; [<a class="ref" href="#briet2006">Briet 2006</a>]; [<a class="ref" href="#feinberg2010">Feinberg 2010</a>]). McGann’s rationale of text as "the dynamic structure of a document as it is realized"
                    also refers to these documentation processes (among others) as essential means
                    by which we come to understand textuality or the rationale of text.</div>

                <div class="counter"><a href="#p5">5</a></div><div class="ptext" id="p5">Before proceeding, it is important to note that text can be realized in different
                    ways. D.F. McKenzie defines text as "verbal, visual, oral, and numeric data, in the form of
                            maps, prints, and music, of archives of recorded sound, of films,
                            videos, and any computer-stored information, everything in fact from
                            epigraphy to the latest forms of discography"
                         [<a class="ref" href="#mckenzie1999">McKenzie 1999</a>, 13]. Further, in the digital envinronment we can process texts as other texts
                    such as sonifying or rasterizing verbal texts, a consequence of "the digital code [that] renders commensurate texts,
                            images, and sounds"
                         [<a class="ref" href="#ernst2012">Enrst 2012</a>, 84]. It is also important to realize that the kinds of text with which McGann
                    and others in digital humanities have been primarily interested are literary,
                    cultural, or aesthetic. As such, these kinds of verbal texts are usually
                    self-reflective or "playfully" aware of their status as realized texts.
                    That is, a literary text such as a poem asks the reader to take into
                    consideration how the poem looks on the page, how the words sound together, how
                    the choice of one word over another or the lack of a word makes meaning. As a
                    result, these kinds of texts have what McGann calls a "generic rationale... to maximize attention to the structure and interplay
                        of the textual orders" – orders such as the linguistic (semantic) and
                    bibliographic (graphical) codes present on a page [<a class="ref" href="#mcgann2001">McGann 2001</a>, 138]. Literary, cultural, and aesthetic texts often emphasize how
                    blurring the boundaries between these elements [<a class="ref" href="#mcgann2001">McGann 2001</a>, 137] can help form the text’s meaning. </div>
                <div class="counter"><a href="#p6">6</a></div><div class="ptext" id="p6">This discussion will address how sound in spoken word audio may be realized in
                    digital information systems. While a wide range of literary, cultural, and
                    aesthetic artifacts may be classified as <em class="term">text</em>, the primary focus
                    for definitions (or rationales) of text in digital humanities have focused on
                    the words of verbal texts in exclusion of other meaning making signifiers.
                    Consider McGann’s footnote to his definition of <em class="term">text</em> in which he
                    admits that phonological and tactile elements (such as how words sound and how a
                    page feels to the touch) are also signifiers but are outside of his "scholarly expertise"
                    [<a class="ref" href="#mcgann2001">McGann 2001</a>, 254]. Meant to help address this sonic gap in
                    McGann's rationale and in order to reconsider the nature of textual rationales
                    more broadly, the rationale of audio textuality considered here is accomplished
                    within the context of scholars working with literary, aesthetic, and cultural
                    aspects of poetry in recorded performances.</div>
            </div>
            <div class="div div0">
                <h1 class="head">3. Rationales of Digital Text</h1>
                <div class="counter"><a href="#p7">7</a></div><div class="ptext" id="p7">Many conversations in digital humanities are concerned with how we model literary
                    texts in systems that reproduce, transmit, display, and analyze text. These
                    discussions typically detail the difficulties creating a model of text that
                    seems to both represent the scholar’s perceived rationale of that text (as
                        "authentic") with the explicitness and consistency that a computer that
                    can "compute" or process those elements requires [<a class="ref" href="#johansson1991a">Johansson et al. 1991a</a>].<a class="noteRef" href="#d938e398">[2]</a> As Willard McCarty reminds us, creating a
                    computationally tractable model of something like "text" is tendentious: it
                        "forc[es] us to confront the radical difference between
                        what we know and what we can specify computationally, leading to the
                        epistemological question <em class="emph">of how we know what we know</em>"
                    [<a class="ref" href="#mccarty2004">McCarty 2004</a>]. Floyd and Renear also note that an ontology for
                    modeling textuality through computers requires a balance between recognizable
                    and computable: the model "need not reflect the latest
                        theories of modern physics, but it should nevertheless at least be
                        internally consistent, and as much as possible avoid clashes with
                        commonsense beliefs"
                    [<a class="ref" href="#floyd2007">Floyd and Renear 2007</a>]. </div>
                <div class="counter"><a href="#p8">8</a></div><div class="ptext" id="p8">In order to better explicate these tensions between a tractable text and an
                    authentic representation of text, I outline two models for computing texts that
                    are widely used by the humanities and library communities and have been
                    critiqued in DH for seemingly inauthentic representations of textuality. The
                    first is a content model called Ordered Hierarchy of Content Objects (OHCO),
                    which has a history in typesetting and printing and was the model upon which the
                    TEI (Text Encoding Initiative) Guidelines for Electronic Text Encoding and
                    Interchange [<a class="ref" href="#tei2014">TEI Consortium 2014</a>] was developed. The second example,
                    Functional Requirements for Bibliographic Records (FRBR), is a model meant to
                    facilitate the organization and discovery of cultural artifacts through library
                    catalogs (International Federation of Library Associations).</div>
                <div class="div div1">
                    <h2 class="head">3.1. Ordered Hierarchy of Content Objects (OHCO)</h2>
                    <div class="counter"><a href="#p9">9</a></div><div class="ptext" id="p9">TEI, one of the first and most widely adopted models of text used in
                        developing information infrastructures in DH was based on the idea of text
                        as an ordered hierarchy of content objects (OHCO) [<a class="ref" href="#derose1990">DeRose et al. 1990</a>]. In the OHCO model, texts are primarily comprised of "linguistic
                            objects" in which form (sections, paragraphs, and quotation blocks)
                        and content (the words that comprise these entities) are separate but
                        related aspects. As a hierarchical model, bigger objects such as chapters or
                        volumes "contain" smaller objects such as paragraphs, which in turn
                        contain other smaller objects such as lists or quotation blocks. This model
                        reflects a concern with procedural practices for verbal texts in typesetting
                        and printing, which entails adding meaningful metadata to a text as
                        meta-instructions for how to format a document [<a class="ref" href="#derose1990">DeRose et al. 1990</a>, 2]. With the OHCO model, computation is facilitated by the
                        structure of these content objects since they can be consistently maintained
                        across different formats or layouts. </div>
                    <div class="counter"><a href="#p10">10</a></div><div class="ptext" id="p10">Rationales of text provide for an understanding of text by which we can
                        evaluate whether a model such as OHCO adequately represents textuality more
                        generally. Critiques of OHCO are concerned with the many ways in which
                        elements of a dynamic text overlap and are therefore poorly represented by a
                        hierarchical, nested structure. Literary texts such as novels and poems, for
                        example, often comprise multiple, overlapping themes or rhyming schemes that
                        fall across lines or stanzas. Due to these debates about the model’s
                        representation of text, the OHCO authors subsequently "retreated from the simple OHCO thesis" and "conclud[ed] that analytical perspectives do seem to exist and do seem
                            to provide fundamental insights into the nature of texts and the
                            methodology of text encoding"
                        [<a class="ref" href="#derose1990">DeRose et al. 1990</a>]. Subsequent refinements to the OHCO model
                        stipulate that while the OHCO model is both practically and empirically
                        valuable to the general community of text consumers, it is perhaps less
                        valuable in the context of literary, cultural, and aesthetic texts where a
                        text can be understood to reflect a rationale of text with a spectrum of
                        determined and determinable dynamics.</div>
                </div>
                <div class="div div1">
                    <h2 class="head">3.2 Functional Requirements for Bibliographic Records (FRBR)</h2>
                    <div class="counter"><a href="#p11">11</a></div><div class="ptext" id="p11">Meant to serve as a model for standards, FRBR was developed primarily as a
                        model or vocabulary for library catalogers and system designers by the
                        International Federation of Library Associations and Institutions (IFLA) in
                        order to standardize practices for finding, identifying, selecting, and
                        obtaining cultural artifacts from libraries [<a class="ref" href="#tillet2004">Tillet 2004</a>, 2]. In an attempt to standardize terminologies for abstract
                        concepts, FRBR includes rules for the specific use of general terms
                        including <em class="term">work</em>, <em class="term">expression</em>,
                            <em class="term">manifestation</em>, and <em class="term">item</em>. In FRBR,
                            <em class="term">work</em> is described as "the story being
                            told in the book, the ideas in a person’s head for a book;"
                        <em class="term">expression</em> is described as a particular translation or edition
                        (scholarly or popular for example) of the work; <em class="term">manifestation</em>
                        is described as a particular publication of the work; and <em class="term">item</em>
                        is described as the "physical object that has paper
                            pages and a binding and can sometimes be used to prop open a door or
                            hold up a table leg"
                        [<a class="ref" href="#tillet2004">Tillet 2004</a>, 2]. In its focus on conceptual
                        entity-relationships, FRBR’s entities reflect an attempt to disambiguate
                        terms by grouping entities by their characteristics as well as by grouping
                        them according to the relationships that tie them together. Thus, multiple
                        editions or <em class="term">expressions</em> of Hamlet can be associated with the
                        same <em class="term">work</em>, making all of the editions findable, identifiable,
                        and obtainable according to that relationship.</div>
                    <div class="counter"><a href="#p12">12</a></div><div class="ptext" id="p12">Though FRBR entities are imagined as "universals", Renear and Dubin show
                        how rationales of text that include textual dynamics at play provide an
                        opportunity for problematizing how the FRBR entities represent texts [<a class="ref" href="#renear2007">Renear and Durbin 2007</a>]. In particular, the authors use the example of
                        the author of a TEI XML (eXtensible Markup Language) document. They discuss
                        a TEI XML document as a complex object that can be simultaneously considered
                        a <em class="term">manifestation</em> (or a new publication of the same content) and
                        an <em class="term">expression </em> (in the event of a scholarly edition that
                        expresses a version of the text that has not been articulated in this way
                        previously). Due to the kinds of ambiguities these examples represent,
                        Renear and Durbin argue that three of the four FRBR entities in Group #1 are
                        problematic since they are not self identical or unique. They argue that the
                        entities are, in fact, <em class="term">roles</em> rather than <em class="term">types</em>.
                        That is, while a <em class="term">type</em> remains a "rigid" property
                        regardless of the context, a <em class="term">role</em>
                        "is brought about by contingent social
                            circumstances" and seems to represent more readily the behaviors
                        that Renear and Durbin observe. </div>
                    <div class="counter"><a href="#p13">13</a></div><div class="ptext" id="p13">Consequent to making a distinction between <em class="term">role</em> and
                            <em class="term">type</em> for the FRBR entities, Renear and Durbin refactor the
                        FRBR types in order to suggest new, more "rigid" or distinct types.
                        Adopting John Searle’s distinction between natural objects, which are
                        presumed independent of context, and social objects, which are contingent on
                        the social dimension of knowing [<a class="ref" href="#searle1995">Searle 1995</a>], Renear and
                        Durbin call these more distinct types <em class="term">symbol sequences</em> (which
                        play the role of realizing a work), <em class="term">physical kinds</em> (which play
                        the role of embodying expressions), and <em class="term">physical objects</em> (which
                        play the role of exemplifying manifestations) [<a class="ref" href="#renear2007">Renear and Durbin 2007</a>].
                        While Renear and Durbin admit to their suggestion’s inconsistencies, the
                        important point here is the extent to which rationales of text are being
                        used both to problematize as well as reimagine how we can develop rigorous
                        text processing systems for the reproduction, transmission, dissemination,
                        and analysis of texts that are both tractable by computers and authentic to
                        humans.</div>
                </div>
            </div>
            <div class="div div0">
                <h1 class="head">4. Rationales of audio text</h1>
                <div class="counter"><a href="#p14">14</a></div><div class="ptext" id="p14">A consideration for rationales of <em class="term">audio</em> text as they are realized
                    through systems for processing audio is also productive, especially since, in
                    the humanities, such systems are often developed for literary, cultural, and
                    aesthetic texts such as oral histories, poetry performances, speeches, and
                    storytelling. In order to better understand what is at stake in terms of
                    rationales for audio text, the following describes the rationale of audio text
                    as it is currently being realized in information systems from three
                    perspectives: (1) through the development of a prototype for sound analysis
                    software in the High Performance Sound Technologies for Access and Scholarship
                    (HiPSTAS) project; (2) as a content model represented by the TEI; and (3) in
                    terms of a library cataloging model for describing audiovisual resources through
                    the BIBFRAME Initiative. </div>
                <div class="div div1">
                    <h2 class="head">4.1 Audio textuality in HiPSTAS</h2>
                    <div class="counter"><a href="#p15">15</a></div><div class="ptext" id="p15">A joint project of the School of Information (iSchool) at the University of
                        Texas at Austin (UT) and the Illinois Informatics Institute (I3) at the
                        University of Illinois at Urbana-Champaign (UIUC), the High Performance
                        Sound Technologies for Access and Scholarship (HiPSTAS) project is
                        developing the ARLO (Adaptive Recognition with Layered Optimization)
                        software. ARLO is a web-based, machine-learning application originally
                        developed for acoustic studies in animal behavior and ecology [<a class="ref" href="#enstrom1993">Enstrom 1993</a>]. In ARLO, the audio text is represented as a
                        spectrogram. Designed to model a bank of hairs in the inner ear and to
                        vibrate at different audio frequencies in response to sound waves, ARLO
                        creates spectrograms by monitoring and then sampling the instantaneous
                        energy of these "hairs" or tuning forks<a class="noteRef" href="#d938e587">[3]</a> and then using this data to create a 2D
                        matrix of values (frequency vs. time). These matrices or spectrograms (see
                        example in Figure 1) show a map of sonic energy across time with each row of
                        pixels representing a frequency band and the color of each pixel
                        representing the numerical value of total energy of that particular
                        frequency (or how much the tuning fork trembles) for that point in time.
                        ARLO uses these spectrograms to model sonic features for machine learning
                        processes including clustering (unsupervised learning) as well as
                        classification (prediction or supervised learning).</div>
                    <div class="counter"><a href="#p16">16</a></div><div class="ptext" id="p16">HiPSTAS was originally funded by the National Endowment for the Humanities as
                        an Institute for Advanced Topics in the Digital Humanities between May 2013
                        and May 2014 for scholars who are interested in using machine-learning
                        software to analyze audio texts of primarily verbal events such as poetry
                        performances, speeches, and storytelling activities. Many of the HiPSTAS
                        participants used ARLO to analyze poetry performances in PennSound, a
                        web-based archive launched by Charles Bernstein and Al Filreis in 2005 as a
                        noncommercial offering of approximately 30,000 downloadable MP3s — mostly as
                        song-length singles. The PennSound recordings are already retrievable both
                        from a library catalog by authors’ names and via Web search engines, but the
                        HiPSTAS participants were primarily interested in analyzing "vocal
                            gestures" in the performances. These gestures such as "the cluster of rhythm and tempo (including word
                                duration), the cluster of pitch and intonation (including
                                amplitude), timbre, and accent"
                             [<a class="ref" href="#bernstein2011">Bernstein 2011</a>, 126], are always dynamically at play and are especially significant for
                        interpreting poetry performances. </div>
                    <div class="counter"><a href="#p17">17</a></div><div class="ptext" id="p17">Poets and scholars describe on online HiPSTAS project pages how searching
                        PennSound "sonically" with ARLO allow them to consider new research
                        questions about the performances including a focus on sonic
                            "para-content" such as pitch and laughter. One participant writes,
                        for example, "I have observed from small-scale analysis
                            that timbre and sound duration are indicators of a stressed syllable.
                            Pitch intensity also correlates with stressed syllables, although not in
                            every instance — I would like to investigate further how much pitch
                            intensity correlates with metrical stress"
                        [<a class="ref" href="#boruszak2014">Boruszak 2014</a>]. Another participant wants to focus on the
                        material artifacts of the recording process, what he calls "para-content audio data" for certain audio texts in
                        order to locate other recordings in PennSound that were recorded as part of
                        a series; he wants "to confirm the suspected provenance
                            of some recordings and to start to bring the recordings together for the
                            first time, perhaps, ever"
                        [<a class="ref" href="#mustazza2014">Mustazza 2014</a>]. A third participant is interested in moments
                        of laughter that "reveal the presence of the audience,
                            emphasize the construction of sounded poems as a the [sic] product of a
                            dialogue between audience and poet, and change significantly the nature
                            of the poem in question"; focused on "close
                            listenings" of four versions of William Carlos Williams’s "This is Just to Say," this participant argues
                            "that a version in which Williams seemed to try to
                            get the audience to laugh and failed showcases the power of laughter at
                            poetry readings, transforming the poem from a whimsical delight to a
                            highly serious, academic reflection on the nature of art and
                            poetry"
                        [<a class="ref" href="#rettberg2014">Rettberg 2014</a>]. Using ARLO’s spectrograms and machine
                        learning processes — which seemed to offer access to these dynamic aspects
                        of audio textuality — the participants began to articulate how these
                        rationales for audio texts might be realized in a system like ARLO.</div>
                    <div class="counter"><a href="#p18">18</a></div><div class="ptext" id="p18">While provocative, systems like ARLO also provide an opportunity for
                        interrogating whether or not they adequately represent both authentic and
                        tractable texts. For instance, identifying sonic patterns in a system such
                        as ARLO is a time-consuming task of finding and labeling training data that
                        adhere to the listener’s understanding of the audio-text’s rationale or
                        dynamic structures. Using these human-generated training examples, ARLO
                        creates a model for labeling new, "unseen" audio examples. In the case
                        of a scholar working with recordings, this could mean marking up a sound
                        recording according to some of the sonic aspects the participants identified
                        above such as variances in pitch, recording noises, or the presence of
                        laughter or applause. For example, Figure 1 shows how one could mark up
                        different voices on spectrogram such as "William Owens" (at point
                            "A") and "Robert Frost" (at point "C") as well as
                        silences (at point "B") in order to teach the machine to model these
                        patterns and to identify or classify more of these sonic patterns of
                        interest in a collection. </div>
                    <div class="counter"><a href="#p19">19</a></div><div class="ptext" id="p19">Labeling examples for machine-learning is ultimately an ontological exercise
                        that requires some standardization. Standardization allows for consistency
                        across machine learning examples as well as results that can be more easily
                        interpreted in terms of a particular discourse community. For instance,
                        instead of compiling their own list of labels, the PennSound scholars chose
                        to use terms provided in the "Transcriptions of
                            Speech" section of the TEI P5 Guidelines because they wanted a
                        set of terms that had been standardized by a community of scholars for whom
                            "mark up" guidelines were the result of sustained study and a
                        concern with representing dynamic rationales of text. Indeed, the elements
                        or terms in the "Transcriptions of Speech"
                        guidelines, which had been vetted by peers who were also versed in both
                        verbal transcription and textual theory seemed to adequately describe the
                            "vocal gestures" also described by Bernstein
                        including <em class="term">Tempo</em>, <em class="term">Rhythm</em>, <em class="term">Loudness</em>,
                            <em class="term">Pitch</em>, and <em class="term">Tension</em> as well as vocal quality
                        attributes such as <em class="term">Whisper</em>, <em class="term">Breathy</em>,
                            <em class="term">Husky</em>, <em class="term">Creaky</em>, <em class="term">Falsetto</em>,
                            <em class="term">Resonant</em>, <em class="term">Unvoiced Laugh or Giggle</em>,
                            <em class="term">Voiced Laugh</em>, <em class="term">Tremulous</em>, <em class="term">Sobbing</em>,
                            <em class="term">Yawning</em>, and <em class="term">Sighing</em>
                        [<a class="ref" href="#tei2014">TEI Consortium 2014</a>].</div>

                    <div class="figure">
                        
                        <div class="ptext"><a href="resources/images/figure01.png" rel="external"><img src="resources/images/figure01.png" alt=""/></a></div>
                    <div class="caption"><div class="label">Figure 1. </div>A “Tagged” Spectrogram in ARLO</div></div>


                    <div class="counter"><a href="#p20">20</a></div><div class="ptext" id="p20">After the poets and scholars had used these TEI terms in ARLO to label
                        two-second samples from PennSound’s 5497 hours of audio, however, they
                        determined that the list was insufficient for adequately describing the
                        sonic aspects of their audio texts.</div>
                    <div class="counter"><a href="#p21">21</a></div><div class="ptext" id="p21">The issue, as described by the participants, was that ARLO’s prototype
                        environment for labeling required them to label snippets of sound as though
                        they were static objects while they understood the audio texts to be dynamic
                        events that reflected a relational context. For instance, one participant
                        might mark a two-second sample "Beatable" with a "High" pitch and
                        another might classify the same sample as "Arrhythmic" with a
                            "Low" pitch. This seeming discrepancy was the result of differing
                        perspectives on the sounds since "High" is only perceived as
                            "High" in relation to "Low" and "Arrhythmic" is only
                        meaningful in relation to "Beatable."<a class="noteRef" href="#d938e777">[4]</a> The participants also
                        wanted to label larger contexts rather than snippets and to tag the
                        recording scenario (such as the sound of the room) over time; the perceived
                        gender of the speaker so that they could mark why they thought a pitch was
                        higher or lower (in relation to how a voice perceived as male or female
                        might register); and the genre of a noise (such as musical or lilting voice)
                        as they perceived it. It quickly became clear that the TEI terms did not
                        provide a way for the participants to label their audio texts as
                        situationally contingent or in a way they felt adequately represented the
                        various audio-textual dynamics they could perceive based on their
                        perspectives in a particular moment in time. Consequently, while
                        participants had rationales of audio-text they wished to access and analyze,
                        their experience in this pilot study seemed to indicate that these
                        rationales were computationally intractable or non-computable in the ARLO
                        system.</div>
                </div>
                <div class="div div1">
                    <h2 class="head">4.2 Audio textuality in the TEI</h2>
                    <div class="counter"><a href="#p22">22</a></div><div class="ptext" id="p22">While the TEI’s "Transcriptions of Speech"
                        guidelines represent one of the few rich content models for reproducing,
                        transmitting, and displaying the verbal content of audio texts in the
                        digital humanities [<a class="ref" href="#johansson1995">Johansson 1995</a>], it was originally
                        developed to produce transcripts or written representations of a stretch of
                        speech. According to extant meetings notes and draft versions, speech
                        encoding guidelines were not originally included in the original TEI P1
                        guidelines [<a class="ref" href="#sperbergmcqueen1990">Sperberg-McQueen and Burnard 1990</a>]. Indeed, when tasked with
                        creating recommendations for its inclusion, the Spoken Text Working Group
                        (STWG) purposefully restricted their guidelines, as much as possible, to the
                        verbal aspects of a recording [<a class="ref" href="#johansson1991a">Johansson et al. 1991a</a>]. Consequently,
                        they labeled prosodic and paralinguistic features such as the vocal gestures
                        Bernstein describes including "quasi vocal things such
                            as laughter, quasi lexical things such as 'mm'"
                        [<a class="ref" href="#johansson1991b">Johansson et al. 1991b</a>] as well as "speaker
                            overlap, pauses, hesitations, repetitions, interruptions",
                        uncertainty, and context [<a class="ref" href="#johansson1995">Johansson 1995</a>] as "problems." Reflecting these early deliberations,
                        the current guidelines still focus on the verbal content of recordings,
                        stating conclusively that "speech regarded as a purely
                            acoustic phenomenon may well require different methods from those
                            outlined here"
                        [<a class="ref" href="#tei2014">TEI Consortium 2014</a>]. To date, these different methods have never been
                        produced within the context of the TEI.</div>
                    <div class="counter"><a href="#p23">23</a></div><div class="ptext" id="p23">From the extant meeting notes surrounding the development of these
                        guidelines, it appears that the TEI STWG found time-based sound dynamics
                        such as pitch, speed, and tone meaningful, but impractical to represent
                        given the TEI’s structure. Notes from the working group’s 1991 meeting
                        reflect the group’s knowledge of the relationship between para-linguistic
                        content and cultural studies in the works of [<a class="ref" href="#svartvik1980">Svartvik and Quirk 1980</a>]
                        and [<a class="ref" href="#tedlock1983">Tedlock 1983</a>], which are heavily cited, but also the
                        understanding that the STWG had to compromise representing these audio-text
                        dynamics in order to stay consistent with the TEI’s underlying OHCO model of
                        textuality and its subsequent use of hierarchical XML (EXtensible Markup
                        Language) elements. The STWG call "performative features
                            such as pitch, speed and vocalization...as analogous to rendition in
                            written texts" and suggest that they be marked similarly in
                        TEI-marked transcriptions, "using milestone tags such as
                                <span class="monospace">&lt;pitch.change&gt;</span>, <span class="monospace">&lt;speed.change&gt;</span> etc."
                        [<a class="ref" href="#johansson1991b">Johansson et al. 1991b</a>]. Likening these performative features to
                        type changes such as italicized or underlined text, the note suggest
                            "milestone" tags that identify these sonic events as clear points
                        in time with a start and an end point instead of as dynamic events that
                        happen in concert with other patterns across time. The end result is similar
                        to the instances in which structural tags produced in the TEI guidelines for
                        text such as <span class="monospace">&lt;p&gt;</span> for paragraph or <span class="monospace">&lt;l&gt;</span> for line cut off themes
                        across novels or truncate rhyming schemes across poems.</div>
                    <div class="counter"><a href="#p24">24</a></div><div class="ptext" id="p24">First marking these sonic phenomena as moments of "change" and, later,
                        as spans to "highlight"
                        [<a class="ref" href="#tei2004">TEI Consortium 2004</a>], the STWG eventually relegated the descriptors
                        outlined above to attributes within the "shift" element
                        (<span class="monospace">&lt;shift&gt;</span>), where they still appear in the P5 TEI Guidelines today
                            [<a class="ref" href="#tei2014">TEI Consortium 2014</a>]. Accordingly, the encoder is not only
                        encouraged to mark these dynamic sound attributes in the encoded transcript
                        as defined points in time but also as "shifts"
                        <em class="emph">outside</em> the "normal" speaking mode [<a class="ref" href="#johansson1991b">Johansson et al. 1991b</a>]. While the guidelines were "not intended to support unmodified every variety of
                            research undertaken upon spoken material now or in the future",
                        these choices show the prominence that models for verbal content in the form
                        of transcriptions have had in the development of content model standards for
                        audio texts in the digital humanities [<a class="ref" href="#tei2014">TEI Consortium 2014</a>]. Like the
                        scholars before them who critiqued the OHCO model of textuality for poetry,
                        our HiPSTAS participants have indicated that these rationales of audio-text
                        cannot adequately represent rationales of audio-text that include the
                        situationally contingent and time-based vocal gestures of poetry performance
                        recordings. </div>
                </div>
                <div class="div div1">
                    <h2 class="head">4.3 Audio texts in the Bibliographic Framework Initiative</h2>
                    <div class="counter"><a href="#p25">25</a></div><div class="ptext" id="p25">The Bibliographic Framework Initiative (BIBFRAME) was founded by the Library
                        of Congress (LC) as a movement to replace the LC’s MARC (Machine-Readable
                        Cataloging) standard<a class="noteRef" href="#d938e898">[5]</a> and
                        represents an example of current thinking concerning how cultural artifacts
                        such as texts and audio-texts are described for discovery in large
                        repositories. Like the FRBR model, the BIBFRAME model seeks to establish a
                        standard model for standards in "all aspects of
                            bibliographic description, data creation, and data exchange . . .
                            includ[ing] accommodating different content models and cataloging rules,
                            exploring new methods of data entry, and evaluating current exchange
                            protocols"
                        [<a class="ref" href="#bibliographic">Bibliographic Framework Initiative</a>]. Like FRBR, the BIBFRAME model also has a
                        central imperative to create models that represent and maximize a user’s
                        ability to find, identify, select, and obtain library holdings such as books
                        and audio files by "differentiat[ing] the conceptual
                            work (a title and author) from the physical details about that work’s
                            manifestation (page numbers, whether it has illustrations)"
                        [<a class="ref" href="#bibliographic">Bibliographic Framework Initiative</a>]. </div>
                    <div class="counter"><a href="#p26">26</a></div><div class="ptext" id="p26">The aspect of the BIBFRAME initiative of concern for this piece is a recent
                        report created by members of the initiative called "BIBFRAME AV Modeling Study: Defining a Flexible Model for Description
                            of Audiovisual Resources"
                        [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>], which is markedly different than FRBR.
                        While the author of the "BIBFRAME AV Modeling
                            Study" is, like FRBR’s authors, very keen to incorporate
                        alternate models that meet both public and scholarly needs for access and
                        discovery methods, her primary model of reference, unlike FRBR’s or the
                        TEI’s, is time-based audiovisual resources rather than verbal texts. </div>
                    <div class="counter"><a href="#p27">27</a></div><div class="ptext" id="p27">As the report indicates, AV resources have medium-specific characteristics
                        that must be taken into consideration in any digital representation. First,
                        they are by nature event-centric and carrier dependent. That is, what is
                        central to the rationale of such recordings is that an event or action (or a
                        continuum of events and actions) that took place in a time and at a place
                        was recorded or "fixed" to a carrier such as a film reel or an audio
                        tape. Van Malssen notes that "while machine dependency
                            is not unique to time-based media, it is an unextractable
                            attribute" that must be taken into account when considering
                        provenance but also for access and discovery in terms of creating playback
                        opportunities at the right speed or color resolution [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 6]. Second, AV resources are more often
                        than not created by and contributed to by many collaborators. Third, these
                        materials are often unique in that they have never been published [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 7]. Fourth, AV resources can be singular
                        items but they are also manifest in the aggregate as collections and can
                        appear on multiple carriers. For example, albums have multiple tracks; songs
                        appear in multiple collections; and long interviews or films are often
                        recorded across multiple tapes or reels [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 8]. Fifth, the audio and moving image media we see today have
                        complicated relationships to their original recordings. Most have been
                        migrated across media formats as older media degenerates and new media
                        evolves. Historical recordings migrated to reel-to-reel tapes, for example,
                        may have first been recorded on glass discs that were shorter in length.
                        Thus, the reel-to-reel tapes do not have a one-to-one relationship to the
                        carriers that originally held the recording. Or, film reels may have been
                        conserved or enhanced in later generations after decades of poor quality
                        viewings. Because of these important characteristics of AV materials, Van
                        Malssen argues that models for cataloguing (and thus discovering) AV must
                        reflect a primary concern with modes of creation and access rather than
                        simply a focus on particular types of content [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 4]. </div>
                    <div class="counter"><a href="#p28">28</a></div><div class="ptext" id="p28">Due to these issues, Van Malssen recommends an event-centric content model
                        for AV resources that takes the physically situated context (e.g., the
                        recording and playback circumstances) into account. If expressions can be
                        described as either work- or event-centric, it would allow for "the inclusion of works, or some work elements as part of
                            the event, but does not require a work be present"
                        [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 24]. This distinction between
                            <em class="term">event</em> and <em class="term">work</em> is exemplified by the
                        difference between an audio recording of a battle that took place in World
                        War II and a filmed reenactment of the same battle. A description of the
                        battle recording would be <em class="term">event-centric</em> since the event took
                        place in space and time and is the object of description at the content
                        level; the filmed re-enactment would be more like the traditional notion of
                        the work in the mind of the creator [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 18]. Van Malssen notes that not treating these catalog descriptions
                        differently results in a blurring of resources: both event and the
                        reenactment would employ the same subject terms (World War II) even though
                        the first <em class="emph">is</em> the event while the second uses the event as
                        content.</div>
                    <div class="counter"><a href="#p29">29</a></div><div class="ptext" id="p29">For audio texts such as recordings of poetry performances, an event-centric
                        description could reshape processes for discovery and possibilities for
                        research. For instance, poetry readings that are recitations of a written
                        text could be marked differently than poetry performances. FRBR identifies
                        an <em class="term">expression</em> as a different edition or translation of a work
                        and the <em class="term">manifestation</em> as the physical embodiment of that
                        expression with the <em class="term">item</em> as "a single
                            exemplar of a manifestation." A marked difference between work
                        and event would be salient in poetry performance studies where the
                        performance of a poem that is also written could be very similar to or very
                        different from the written text – either a new expression or a whole new
                        work (that is the event). For example, in Ken Sherwood’s analysis of the
                        recordings and transcriptions of Amiri Baraka, Kamau Brathwaite, and Cecilia
                        Vicuña, he speaks of "emergent performance
                            events" as different works in comparison to poetry recitations,
                        which he considers oral versions (or variant expressions) of the written
                        text [<a class="ref" href="#sherwood2006">Sherwood 2006</a>]. A performance, Bernstein argues "opens up the potential for shifting frames, and the shift
                            of frame is itself perceived as a performative gesture . . . the implied
                            or possible performance becomes a ghost of the textual
                            composition"
                        [<a class="ref" href="#bernstein2011">Bernstein 2011</a>, 127]. A model that could be either
                        event- or work-centric could serve to help identify these kinds of hybrid
                        situations in which an event gives rise to a work or vice versa, creating an
                        entirely new, but related, entity. </div>
                    <div class="counter"><a href="#p30">30</a></div><div class="ptext" id="p30">It is clear that our print-based, logocentric biases preclude us from
                        facilitating new kinds of discovery and analysis with alternate media, but
                        seeing these biases also makes it apparent that we are building models of
                        textuality in general that remain insufficiently poor. The attempt in the
                        HiPSTAS project to create an infrastructure for analyzing audio patterns in
                        audio texts illustrates the importance in the humanities for rationales of
                        audio text that engage audio as events that may make meaning differently by
                        means of markedly different reception scenarios. Finding and making meaning
                        with audio texts can include a consideration for sound dynamics that can
                        only be perceived through time such as pitch, timbre, and intonation as well
                        as the importance of material recording scenario artifacts, all of which
                        could be considered "noise" and essentially rendered undiscoverable in
                        the context of systems that model all texts as if they are static, verbal
                        documents. As a culture, we have become adept at modeling textuality in
                        terms of a print-based paradigm in which texts are discrete entities (in
                        terms of both time and space) of verbal content. We are arguably less adept
                        at modeling time-based or three-dimensional media, which we still insist on
                        fixing in time and translating into words, either through metadata or
                        through transcripts.<a class="noteRef" href="#d938e996">[6]</a> Discussions concerned with access and scholarship with AV
                        materials provides for an opportunity for expanding our thinking about these
                            "other" texts but also how representations of traditional (or
                        book-like) verbal texts are equally insufficient in the digital environment.
                    </div>
                </div>
            </div>
            <div class="div div0">
                <h1 class="head">5. Towards [Other] Rationale[s] of [Audio] Text</h1>
                <div class="counter"><a href="#p31">31</a></div><div class="ptext" id="p31">The expanding web, advancing opportunities for networking within and across
                    library collections through Linked Data, and our increasingly complex needs for
                    discovering and analyzing all types of library holdings has resulted in a
                    general re-evaluation of how we model all types of cultural artifacts through
                    information systems. Situating the above reflections on the rationale of audio
                    text in the context of Renear and Durbin’s recommendations for roles in FRBR and
                    the AV model recommendations for describing events in the LC’s BIBFRAME standard
                    provides for an opportunity to reconsider methods for representing textuality
                    more generally as always situated and contingent in information systems.
                    Specifically, the following section introduces three aspects of textuality that
                    could be foregrounded through event-centric content and discovery models:
                    collective intentionality, emergent performativity, and indexical
                    performativity.</div>
                <div class="div div1">
                    <h2 class="head">5.1 Collective intentionality</h2>
                    <div class="counter"><a href="#p32">32</a></div><div class="ptext" id="p32">With an event-centric model, textual events could be described as social
                        objects that reflect collective intentionalities. Arguing that the role a
                            "natural" object plays is determined by contingent social
                        circumstances, Renear and Durbin cite J.R. Searle’s understanding of these
                        circumstances as the "collective intentionality" of producers,
                        transmitters, and consumers who shape the role an object plays in a system
                            ([<a class="ref" href="#searle1995">Searle 1995</a>], quoted in [<a class="ref" href="#renear2007">Renear and Durbin 2007</a>]).
                        This notion of collective intentionality is also essential in social text
                        theories such as Martha Nell Smith’s ideas concerning triangular textuality
                            ("the influence of biography, reception, and textual
                            reproduction") in Emily Dickinson’s work [<a class="ref" href="#smith1992">Smith 1992</a>, 2]; in the context of the Ivanhoe Game in which the reader’s
                        interpretations are essential to the perceived rationale of text [<a class="ref" href="#mcgann2001">McGann 2001</a>]
                        [<a class="ref" href="#drucker2003">Drucker and Rockwell 2003</a>]; or in D.F. McKenzie’s insistence that texts
                        serve as signposts for spatio-temporality, as they alert "us to the roles of institutions and their complex
                            structures in affecting the forms of social discourse, past and
                            present"
                        [<a class="ref" href="#mckenzie1999">McKenzie 1999</a>, 15]. In defining each manifestation as
                        the fixing or recording of socio-textual events, McGann, McKenzie, Smith,
                        and others are discussing texts as social objects in much the same way as
                        Renear and Durbin who are arguing that the social and cultural circumstances
                        that help produce texts and our understandings of a text should be included
                        in computational models for texts. </div>
                    <div class="counter"><a href="#p33">33</a></div><div class="ptext" id="p33">While it would seem that such social circumstances are beyond the
                        codifications of a bibliographic standard for access, there are emerging
                        models for discovering AV that are promising. Van Malssen cites
                            <em class="term">indecs</em>, a project of the European Community Info 2000
                        initiative, as an AV model that adequately "places
                            emphasis on the role that events play in the creation of a
                            resource" by using the expression entity to describe events as
                            "‘creating’ events (an event which results in the
                            making of a creation), ‘using’ events (events which results [sic] in the
                            use of a resource), or ‘transforming’ events which involve the use of
                            one creation in the making of another)"
                        [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 19]. Marking the role of event is
                        markedly different even than the promising W3C Provenance Data Model
                        (PROV-DM), which is a framework that includes "information about entities, activities, and people involved in
                            producing a piece of data or thing, which can be used to form
                            assessments about its quality, reliability or trustworthiness"
                        [<a class="ref" href="#provdm">PROV-DM</a>]. Designed to model the relationships involved in the
                        creation of items, PROV-DM is organized into six components that include the
                        following: "(1) entities and activities, and the time at
                            which they were created, used, or ended; (2) derivations of entities
                            from entities; (3) agents bearing responsibility for entities that were
                            generated and activities that happened; (4) a notion of bundle, a
                            mechanism to support provenance of provenance; (5) properties to link
                            entities that refer to the same thing; and, (6) collections forming a
                            logical structure for its members"
                        [<a class="ref" href="#provdm">PROV-DM</a>]. Like the FRBR model, however, PROV-DM does not
                        designate the role of events in terms such as "creating events,"
                        "transforming events," and "using events" but rather the
                        manifestations such as texts, paintings, or photographs that result from
                        these events. Thus, while a more robust model such as PROV-DM can provide a
                        model for text that foregrounds the results of collective intentionalities
                        (and thus records its occurrence), the event-centric information concerning
                        the roles these events play in relationship to each other and to the objects
                        they effect remains obfuscated. </div>
                </div>
                <div class="div div1">
                    <h2 class="head">5.2 Emergence</h2>
                    <div class="counter"><a href="#p34">34</a></div><div class="ptext" id="p34">A model of textuality that represents text as a spatial and temporal
                        phenomenon might allow for interactions and representations in a digital
                        environment that, rather than insisting on fixity, foreground principles of
                        emergence. For example, the AV model recommendations for BIBFRAME note that
                        FRBR does not provide a model for describing an aggregate manifestation that
                        comprises two or more distinct expressions such as when two different parts
                        of a recording are recorded or "fixed" at different times and different
                        places or when different tracks on a recording are compilations of wholly
                        different works, a scenario that is not far removed from similar instances
                        of volumes of poetry or short stories, which have been republished and
                        reissued. This inadequacy comes into greater relief as we begin to think
                        about the creating, using, and transforming events that give rise to whole
                        new works.</div>
                    <div class="counter"><a href="#p35">35</a></div><div class="ptext" id="p35">The recommendations for a BIBRAME AV model attempts to expand on the notion
                        of fixity that is inherent to the FRBR model. Discussing a digital video
                        file that might have singular or multiple video and audio tracks plus a
                        subtitle track, the AV model recommendations cite the concept of
                            <em class="term">essence</em> as it is used in the PBCore (Public Broadcasting
                        Metadata Dictionary Project) and EBU (European Broadcasting Unit) Core
                        models for broadcast collections as a more robust concept for an
                        event-centric model since it typically includes information about both the
                        content and carrier as well as enabling the description of multiple
                        instantiations of a given content item, such as a broadcast that is
                        repeatedly aired at different times. The AV model recommendations favor the
                        essence model as one that "is as much about the
                            bitstream or signal as it is about the content carried in that
                            stream" because it "is expressed in these
                            models through sets of carrier sub-elements . . . which can be repeated
                            for different essence types found in that carrier"
                        [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 18]. </div>
                    <div class="counter"><a href="#p36">36</a></div><div class="ptext" id="p36">This notion of essence corresponds to John Bryant’s definition of verbal
                        texts as "fluid" or as a "flow of energy" rather than a product or
                        a "conceptual thing or actual set of things or even
                            discrete events"
                        [<a class="ref" href="#bryant2002">Bryant 2002</a>, 61]. According to this definition, the
                        aggregated text comprises multiple versions in manuscript and print, various
                        notes and letters and comments of contemporaries or current readers, as well
                        as an element of what I have called <em class="term">textual performance</em>
                        [<a class="ref" href="#clement2011">Clement 2011</a>] or a concept of textuality as it is manifested
                        or performed in real time and space with a collaborative audience. By
                        developing models that expand notions of fixity as an essential element, we
                        allow manifestations to be aggregate and contingent, a representation for
                        text that allows for new modes of discovery and access. </div>
                </div>
                <div class="div div1">
                    <h2 class="head">5.4 Indexical performativity</h2>
                    <div class="counter"><a href="#p37">37</a></div><div class="ptext" id="p37">As discussed, according to the recommendations for a BIBFRAME AV model, an AV
                        object should always be described in terms of the event of its realization,
                        in terms of how it has been and could be realized on a particular carrier or
                        format (such as a vinyl record or a CD), or in terms of a particular
                        playback system (such as a record player or CD player). As such, every
                        manifestation becomes indexical because each points to these events or
                        technological protocols that generated the item. As such, the nature of an
                        object’s identification as an "item" would be based in part on the
                        information surrounding the contingent circumstances of its realization. For
                        instance, in order to enable "authentic access and
                            preservation," the AV model recommendations cite a need for
                        software systems that not only describe granular features of certain formats
                        such as "audio reel, number of tracks, playback speed,
                            reel size, etc.", but also the technical characteristics of
                        carriers in order "to enable identification of the
                            appropriate playback equipment" that can respond to or make
                        manifest these features [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 24]. </div>
                    <div class="counter"><a href="#p38">38</a></div><div class="ptext" id="p38">Accordingly, these aspects of an object’s indexicality are also performative
                        in a digital environment since they create how we understand the structure
                        of the event of an object’s instantiation. Wolfgang Ernst describes this
                        kind of performativity in the digital environment as the extent to which
                        code plays a role as text, as image, as audio, and so on; from this
                        perspective, "rigid text is replaced by an operative
                            mathematics"
                        [<a class="ref" href="#ernst2012">Enrst 2012</a>, 87]. By drawing attention to the manner in
                        which code effects commensurability among digital "items" such as text,
                        images, and sound, Ernst considers "the structure of an
                            archive whose essence, the closer one looks [as] less the archived
                            material per se than a dynamic conception of the idea of the
                            archive"
                        [<a class="ref" href="#ernst2012">Enrst 2012</a>, 83]. This is to say that the very nature of
                        digital materiality requires that a model for "item" (through attribute
                        and values) be applied on the level of the bitstream in order for any text
                        to be realized as such. This aspect of the item’s indexical performativity
                        is also identified in Renear and Durbin’s assertion that "items are the things, whatever their nature (physical,
                            abstract, or metaphorical), which play the role in bibliographic control
                            that FRBR assigns to items"
                        [<a class="ref" href="#floyd2007">Floyd and Renear 2007</a>]. In both cases, the attributes and relations of
                        an item (whether on the level of its physical or digital instantiation) that
                        effect its manifestation are also what would define its role as an item in a
                        system like FRBR or BIBFRAME and our understandings of its
                        "itemness".</div>
                    <div class="counter"><a href="#p39">39</a></div><div class="ptext" id="p39">When modeled as event-centric, these attributes and relations of an item are
                        directly affected by changing data models that demand updated software and
                        hardware with changing protocols and algorithms for the constant realizing
                        of items over time and across systems. For instance, as Jonathon Sterne
                        argues, "the transformations effected by MP3 encoding
                            are themselves heavily-directed cultural practices. MP3s contain within
                            them a whole philosophy of audition [based on the limitations of human
                            hearing] and a praxeology of listening . . . [that] emphasizes
                            distraction over attention and exchange over use"
                        [<a class="ref" href="#sterne2006">Sterne 2006</a>, 828]. Noting that the MP3 is a container
                        for an audio digital recording that has been compressed with the use of a
                        mathematical model that takes human auditory perception into account, Sterne
                        writes that the "most compelling part of the MP3 is the
                            psychoacoustic model encoded within it . . . It preemptively discards
                            data in the sound file that it anticipates the body will discard later,
                            resulting in a smaller file"
                        [<a class="ref" href="#sterne2006">Sterne 2006</a>, 833]. Depending on what aspect of the sound
                        recording one seeks to address, therefore, the MP3, which is typically
                        categorized in traditional models such as FRBR as a derivative item of the
                        same manifestation, could be understood as actually realizing a different
                        event: one without the soundscape that exists beyond human hearing.</div>
                    <div class="counter"><a href="#p40">40</a></div><div class="ptext" id="p40">This notion of an event-centric indexicality can be made more broadly
                        applicable to all kinds of digital textuality. Michael Witmore has written
                        that "a text is a text because it is massively
                            addressable at different levels of scale . . . one can query a position
                            within the text at a certain level of abstraction" such as a word
                        or a line, but also on the level of a theme or a character [<a class="ref" href="#witmore2010">Witmore 2010</a>]. In a digital context in which we are attempting
                        to model textuality for discoverability and analysis, a text can also be
                        understood as massively and differently addressable and therefore indexical
                        according to how the protocols we design in the system instantiate it at a
                        given point and time. Consider Witmore’s definition of text addressability
                        in relation to Sterne’s description of the MP3 and McGann’s "Rationale of Hypertext" in which a central
                        identifying feature of the hypertext is that "[un]like a
                            traditional book or set of books, the HyperText need never be
                            ‘complete’"; rather, the hypertext by nature "will evolve and change over time, it will gather new bodies of
                            material, its organizational substructures will get modified";
                        and, "[u]nlike a traditional edition, a HyperText is not
                            organized to focus attention on one particular text or set of texts. It
                            is ordered to disperse attention as broadly as possible"
                        [<a class="ref" href="#mcgann2001">McGann 2001</a>, 71]. With such a text, Witmore’s levels of
                        abstraction are exponentially complicated by the digital text’s
                        complexities. The digital text can become differently discernible and
                        interpreted by different audiences with each different manifestation or code
                        performance. In web pages created "on the fly" with PHP (Hypertext
                        Preprocessor), for example, the same URI (Uniform Resource Identifier) or
                        URL (Uniform Resource Locator) could take a reader to a different textual
                        instantiation each time. As McGann reminds us, with hypertext, "[o]ne is encouraged not so much to find as to make order
                            -- and then to make it again and again, as established orderings expose
                            their limits . . . [the edition] will incorporate and then go beyond its
                            initial design and management"
                        [<a class="ref" href="#mcgann2001">McGann 2001</a>, 71]. Event-centric attributes and relations
                        have an indexical performativity across all texts (written, verbal and AV
                        materials) in that the technological context in which the text has been
                        created and "served" or delivered to the scholar is not only reflected
                        in the item, it creates our understanding of the item’s
                            <em class="term">itemness</em> (such as "a page created on the fly") and
                        therefore directly impacts our understandings of its textuality more
                        generally.</div>
                </div>
            </div>
            <div class="div div0">
                <h1 class="head">6. Conclusion</h1>
                <div class="counter"><a href="#p41">41</a></div><div class="ptext" id="p41">There is an aside in McGann’s "Rationale of Hypertext"
                    that almost goes unnoticed. In discussing the myriad extensibilities that
                    hypertext employs that "go beyond its initial
                        design," McGann writes, "<em class="emph">Someone will have
                            to manage it</em>..."
                    [<a class="ref" href="#mcgann2001">McGann 2001</a>, 71]. This conclusion concerns that
                        "someone" or, rather, the realities and practicalities of managing
                    computationally tractable as well as authentic and recognizable, texts in an
                    information system. Renear and Durbin, for example, note that FRBR is a
                    guideline for practice, an "extraordinarily promising and
                        compelling...general ontology," which never claims its entities
                        <em class="emph">are</em> types — and thus, Renear and Durbin concede, their argument
                    for articulating them as <em class="term">roles</em> could be considered, at best, an
                    academic exercise, and, at worst "willfully obtuse"
                    [<a class="ref" href="#renear2007">Renear and Durbin 2007</a>]. Similarly, Van Malssen writes that the recommended
                    BIBFAME AV model is meant to be "intuitive enough so a
                        trained professional user is able to interpret it and easily make decisions
                        about how to apply it to a given content type"
                    [<a class="ref" href="#vanmalssen2014">Van Malssen 2014</a>, 25]. The recommendations are an attempt to
                    suggest a model that is flexible enough to describe film and audio as well as
                    books in an effort to create practical guidelines or guidelines for real
                    information infrastructures that are managed by and used by real practitioners
                    and scholars. </div>
                <div class="counter"><a href="#p42">42</a></div><div class="ptext" id="p42">Yet, a concern for the ontological issues that shape information management
                    systems is increasingly important since widely used ontologies like FRBR and
                    BIBFRAME and semantics like the TEI often impact other practicalities such as
                    data interchange in Linked Data and the Semantic Web. For instance, projects
                    such as ARC (Advanced Research Consortium), which is the umbrella organization
                    for NINES, 18thCONNECT, ModNets and other communities who are trying to both
                    shape and facilitate digital scholarship in the humanities,<a class="noteRef" href="#d938e1285">[7]</a> model their RDF (Resource
                    Description Framework) data models for Linked Data on the Dublin Core standards,
                    which are, in turn, heavily influenced by FRBR [<a class="ref" href="#chaudhri2009">Chaudhri 2009</a>]. </div>
                <div class="counter"><a href="#p43">43</a></div><div class="ptext" id="p43">As such, this discussion serves as a provocation rather than a practical how-to.
                    I am noting here that digital humanities has a tradition of problematizing our
                    understanding of textuality through the design of information systems. I am also
                    suggesting that these efforts have been almost exclusively performed in the
                    context of rationales for verbal texts that still, in many (if not most) cases,
                    look like books or pages of books. Scholars within this tradition have an
                    opportunity to ask more questions and to create different, more encompassing
                    solutions within the context of designing systems for AV materials.</div>
                <div class="counter"><a href="#p44">44</a></div><div class="ptext" id="p44">To conclude, both the Council for Library and Information Resources (CLIR) and
                    the Library of Congress (LC) have issued reports detailing the dire state of
                    access and preservation with sound recordings. Both have called for "new technologies for audio capture and automatic metadata
                        extraction"
                    [<a class="ref" href="#rumsey2004">Rumsey et al. 2004</a>] with a "focus on developing,
                        testing, and enhancing science-based approaches to all areas that affect
                        audio preservation"
                    [<a class="ref" href="#loc2012">The Library of Congress 2012</a>, 15] in order to help relieve backlogs of
                    undescribed (even though digitized) audio collections and to facilitate better
                    means for access and discovery. One of the results of these reports is an
                    urgency to re-evaluate how we develop metadata frameworks that facilitate access
                    to audio. One means of re-evaluation is a reconsideration of our rationales of
                    text. What if all entities were modeled as dynamic events? Would notions of
                    collective intentionality, emergence, and indexical performativity foreground
                    our searches and shape what we are able to find? Text is central to the
                    Humanities, but as the editor of this special issue notes, "digitization
                    remediates all analog sources into a common binary format," a situation which
                    serves as an invitation to think through these remediations towards the
                    development of future information systems that will continue to shape new and
                    different rationales of text.</div>
            </div>
            <div class="div div0">
                <h1 class="head">Acknowledgments</h1>
                <div class="counter"><a href="#p45">45</a></div><div class="ptext" id="p45">Acknowledgments Thank you to the National Endowment for the Humanities for its
                    generous support of the HiPSTAS project. Thank you as well to my collaborators
                    on the HiPSTAS project, David Tcheng, Loretta Auvil, Tony Borries, and David
                    Enstrom.</div>
            </div>
        
        
            

        
    </div>
<div id="notes"><h2>Notes</h2><div class="endnote" id="d938e264"><span class="noteRef">[1]</span>Audio is best defined as sound that has been recorded,
                        transmitted, or reproduced.</div><div class="endnote" id="d938e398"><span class="noteRef">[2]</span>A computational model of text, in Willard
                        McCarty’s terms, would be both completely explicit and absolutely consistent
                        as well as manipulable.</div><div class="endnote" id="d938e587"><span class="noteRef">[3]</span> The instantaneous energy
                            is then factored by summing the fork’s potential energy or the
                            deflection of the fork and its kinetic energy based on the speed of the
                            movement, per second.</div><div class="endnote" id="d938e777"><span class="noteRef">[4]</span>These results are discussed
                            in detail in [<a class="ref" href="#clement2014a">Clement 2014</a>].</div><div class="endnote" id="d938e898"><span class="noteRef">[5]</span>The MARC standard, which was originated by the LC,
                            is a set of digital formats for describing and cataloguing items that
                            has been an international standard since the 1970s.</div><div class="endnote" id="d938e996"><span class="noteRef">[6]</span>See more discussions of these perceived
                            inadequacies in [<a class="ref" href="#good2006">Good 2006</a>] and [<a class="ref" href="#nyhan2014">Nyhan and Flynn 2014</a>].</div><div class="endnote" id="d938e1285"><span class="noteRef">[7]</span>ARC is
                        described at <a class="ref" href="http://idhmc.tamu.edu/arcgrant/" onclick="window.open('http://idhmc.tamu.edu/arcgrant/'); return false">http://idhmc.tamu.edu/arcgrant/</a>.</div></div><div id="worksCited"><h2>Works Cited</h2><div class="bibl"><span class="ref" id="bauman1975"><!-- close -->Bauman 1975</span> Bauman, R. "Verbal
                        Art as Performance." In <cite class="title italic">American
                        Anthropologist</cite>, New Series, 77, no. 2 (June 1975): 290-311.</div><div class="bibl"><span class="ref" id="bernstein2011"><!-- close -->Bernstein 2011</span> Bernstein, C. <cite class="title italic">Attack of the Difficult Poems: Essays and Inventions</cite>.
                    University Of Chicago Press, 2011.</div><div class="bibl"><span class="ref" id="bibliographic"><!-- close -->Bibliographic Framework Initiative</span> Bibliographic Framework Initiative. Library of Congress (May 15, 2014). <a class="ref" href="http://www.loc.gov/bibframe/" onclick="window.open('http://www.loc.gov/bibframe/'); return false">http://www.loc.gov/bibframe/</a>.</div><div class="bibl"><span class="ref" id="boruszak2014"><!-- close -->Boruszak 2014</span> Boruszak, J. <a class="ref" href="https://sites.google.com/site/nehhipstas/project-pages/jeff-boruszak" onclick="window.open('https://sites.google.com/site/nehhipstas/project-pages/jeff-boruszak'); return false">https://sites.google.com/site/nehhipstas/project-pages/jeff-boruszak</a></div><div class="bibl"><span class="ref" id="briet2006"><!-- close -->Briet 2006</span> Briet, S. <cite class="title italic">What is
                        Documentation? English Translation of the Classic French Text</cite>.
                    Translated and edited by R. E. Day and L. Martinet. Lanham, MD: Scarecrow Press,
                    2006.</div><div class="bibl"><span class="ref" id="bryant2002"><!-- close -->Bryant 2002</span> Bryant, J. <cite class="title italic">The
                        Fluid Text: A Theory of Revision and Editing for Book and Screen</cite>.
                    Ann Arbor: University of Michigan Press, 2002.</div><div class="bibl"><span class="ref" id="bryant2011"><!-- close -->Bryant 2011</span> Bryant, J. "Where
                        Is the Text of America? Witnessing Revision and the Online Critical
                        Archive." In <cite class="title italic">The American Literature Scholar in
                        the Digital Age</cite>, edited by Amy E. Earhart and Andrew Jewell. Ann
                    Arbor: University of Michigan Press, 2011. </div><div class="bibl"><span class="ref" id="buckland1997"><!-- close -->Buckland 1997</span> Buckland, M. "What is a ‘document’?"
                    <cite class="title italic">Journal of the American Society for Information
                        Science</cite> 48, no. 9 (1997): 804-809.</div><div class="bibl"><span class="ref" id="buzetti2006"><!-- close -->Buzzetti and McGann 2006</span> Buzzetti, D. and McGann,
                    J. J. "Critical Editing in a Digital Horizon." In
                        <cite class="title italic">Electronic Textual Editing,</cite> edited by Lou
                    Burnard, Katherine O’Brien O’Keeffe, and John Unsworth. New York: Modern
                    Language Association of America, 2006. <a class="ref" href="http://www.tei-c.org/About/Archive_new/ETE/index.xml" onclick="window.open('http://www.tei-c.org/About/Archive_new/ETE/index.xml'); return false">http://www.tei-c.org/About/Archive_new/ETE/index.xml</a>.</div><div class="bibl"><span class="ref" id="chaudhri2009"><!-- close -->Chaudhri 2009</span> Chaudhri, Talat. "Assessing FRBR in Dublin Core Application Profiles."
                    Ariadne 58 (2009): n. pag. http://www.ariadne.ac.uk.</div><div class="bibl"><span class="ref" id="clement"><!-- close -->Clement</span> Clement, T. E. "When
                        Texts of Study are Audio Files: Digital Tools for Sound Studies in
                        DH" In <cite class="title italic">A New Companion to Digital
                        Humanities</cite> (Blackwell Companions to Literature and Culture). Susan
                    Schreibman, Ray Siemens and John Unsworth (eds.) (accepted for
                    publication).</div><div class="bibl"><span class="ref" id="clement2011"><!-- close -->Clement 2011</span> Clement, T. E. "Knowledge Representation and Digital Scholarly Editions in Theory and
                        Practice."
                    <cite class="title italic">Journal of the Text Encoding Initiative</cite> 1, no. 1
                    (June 2011). <a class="ref" href="http://jtei.revues.org/203" onclick="window.open('http://jtei.revues.org/203'); return false">http://jtei.revues.org/203</a>.</div><div class="bibl"><span class="ref" id="clement2014a"><!-- close -->Clement 2014</span> Clement, T. E. "The Ear and the Shunting Yard: Meaning Making as Resonance in Early
                        Information Theory."
                    <cite class="title italic">Information &amp; Culture</cite> 49.4 (2014):
                    401-426.</div><div class="bibl"><span class="ref" id="clement2014b"><!-- close -->Clement et al. 2014</span> Clement, T., Tcheng, D.
                    Auvil, L. and Borries, T. "High Performance Sound
                        Technologies for Access and Scholarship (HiPSTAS) in the Digital
                        Humanities" <cite class="title italic">Proceedings of the 77th Annual ASIST
                        Conference</cite>, Seattle, WA, October 31-November 5, 2014.1.</div><div class="bibl"><span class="ref" id="council2012"><!-- close -->Council on Library and Information Resources and The Library of                     Congress 2012</span> Council on Library and Information Resources and The
                    Library of Congress.<cite class="title italic"> National Recording Preservation
                        Plan</cite>. Washington, DC: Council on Library and Information Resources
                    and The Library of Congress, 2012.</div><div class="bibl"><span class="ref" id="derose1990"><!-- close -->DeRose et al. 1990</span> DeRose, S. Durand, D. G.,
                    Renear, A. H. "What Is Text, Really?"
                    <cite class="title italic">Journal of Computing in Higher Education</cite> 1, no. 2
                    (1990): 3–26.</div><div class="bibl"><span class="ref" id="drucker2002"><!-- close -->Drucker 2002</span> Drucker, J. "Theory as Praxis: The Poetics of Electronic Textuality."
                    <cite class="title italic">Modernism/modernity</cite> 9, no. 4 (2002): 683–91.
                    doi:10.1353/mod.2002.0069.</div><div class="bibl"><span class="ref" id="drucker2003"><!-- close -->Drucker and Rockwell 2003</span> "Introduction; Reflections on the Ivanhoe Game."
                    <cite class="title italic">Text Technology</cite> 12.2 (2003): vii-xviii.</div><div class="bibl"><span class="ref" id="ernst2012"><!-- close -->Enrst 2012</span> Ernst, W. <cite class="title italic">Digital
                        Memory and the Archive</cite>. Minneapolis: Univ Of Minnesota Press,
                    2012.</div><div class="bibl"><span class="ref" id="enstrom1993"><!-- close -->Enstrom 1993</span> Enstrom, D. A. "Female Choice for Age-Specific Plumage in the Orchard Oriole: Implications
                        for Delayed Plumage Maturation."
                    <cite class="title italic">Animal Behaviour</cite> 45, no. 3 (March 1993): 435–42.
                    doi:10.1006/anbe.1993.1055.</div><div class="bibl"><span class="ref" id="feinberg2010"><!-- close -->Feinberg 2010</span> Feinberg, M. "Two kinds of evidence: how information systems form rhetorical
                        arguments."
                    <cite class="title italic">Journal of Documentation</cite> 66, no. 4 (2010):
                    491-512.</div><div class="bibl"><span class="ref" id="floyd2007"><!-- close -->Floyd and Renear 2007</span> Floyd, I. and Renear, A. H.
                        "What Exactly is an Item in the Digital World?"
                    Poster presented at the Annual Meeting of the Association for Information
                    Science and Technology, Milwaukee, Wisconsin, October 19-24, 2007.</div><div class="bibl"><span class="ref" id="frohmann2004"><!-- close -->Frohmann 2004</span> Frohmann, B. <cite class="title italic">Deflating Information: From Science Studies to Documentation</cite>.
                    Toronto: University of Toronto Press, Scholarly Publishing Division,
                    2004.</div><div class="bibl"><span class="ref" id="goldfarb1981"><!-- close -->Goldfarb 1981</span> Goldfarb, C.. "A generalized approach to document markup." Proceedings of the ACM
                    SIGPLAN--SIGOA Symposium on Text Manipulation. New York: ACM (1981):
                    68-73.</div><div class="bibl"><span class="ref" id="good2006"><!-- close -->Good 2006</span> Good, F. "Voice, ear
                        and text: words, meaning and transcription." In R. Perks &amp; A.
                    Thomson, eds. <cite class="title italic">The Oral History Reader</cite>. New York:
                    Routledge, 2006: 362–373.</div><div class="bibl"><span class="ref" id="johansson1995"><!-- close -->Johansson 1995</span> Johansson, S. "The Encoding of Spoken Texts."
                    <cite class="title italic">Computers and the Humanities</cite> 29, no. 2 (1995):
                    149–58.</div><div class="bibl"><span class="ref" id="johansson1991a"><!-- close -->Johansson et al. 1991a</span> Johansson, S. Burnard,
                    L., Edwards, J., Rosta, A. "TEI AI2 W1 Working paper on
                        spoken texts University College London." TEI Consortium (October,
                    1991a). <a class="ref" href="http://www.tei-c.org/Vault/AI/ai2w01.txt" onclick="window.open('http://www.tei-c.org/Vault/AI/ai2w01.txt'); return false">http://www.tei-c.org/Vault/AI/ai2w01.txt</a>.</div><div class="bibl"><span class="ref" id="johansson1991b"><!-- close -->Johansson et al. 1991b</span> Johansson, S. Burnard,
                    L., Edwards, J., Rosta, A. "TEI AI2 M1 Minutes of Meeting
                        Held at University of Oslo." TEI Consortium (9-10 August 1991b). <a class="ref" href="http://www.tei-c.org/Vault/AI/ai2m01.txt" onclick="window.open('http://www.tei-c.org/Vault/AI/ai2m01.txt'); return false">http://www.tei-c.org/Vault/AI/ai2m01.txt</a>.</div><div class="bibl"><span class="ref" id="kirschenbaum2008"><!-- close -->Kirschenbaum 2008</span> Kirschenbaum, M. G. <cite class="title italic">Mechanisms: New Media and the Forensic Imagination.</cite>
                    Cambridge, MA: MIT Press, 2008.</div><div class="bibl"><span class="ref" id="liu2004"><!-- close -->Liu 2004</span> Liu, A. "Transcendental
                        Data: Toward a Cultural History and Aesthetics of the New Encoded
                        Discourse."
                    <cite class="title italic">Critical Inquiry</cite> 31, no. 1 (2004): 49–84.</div><div class="bibl"><span class="ref" id="mccarty2004"><!-- close -->McCarty 2004</span> McCarty, W. "Modeling: A Study in Words and Meanings." In <cite class="title italic">Companion to Digital Humanities</cite> (Blackwell Companions to Literature
                    and Culture), edited by Susan Schreibman, Ray Siemens, and John Unsworth.
                    Oxford: Blackwell Publishing Professional, 2004. <a class="ref" href="http://www.digitalhumanities.org/companion/" onclick="window.open('http://www.digitalhumanities.org/companion/'); return false">http://www.digitalhumanities.org/companion/</a>.</div><div class="bibl"><span class="ref" id="mcgann1983"><!-- close -->McGann 1983</span> McGann, J. J. <cite class="title italic">A
                        Critique of Modern Textual Criticism</cite>. Chicago: University of Chicago
                    Press, 1983.</div><div class="bibl"><span class="ref" id="mcgann1991"><!-- close -->McGann 1991</span> McGann, J. J. <cite class="title italic">The
                        Textual Condition</cite>. Princeton, N.J: Princeton University Press,
                    1991.</div><div class="bibl"><span class="ref" id="mcgann1995"><!-- close -->McGann 1995</span> McGann, J. J. "The
                        Rationale of HyperText," May 6, 1995. <a class="ref" href="http://www.iath.virginia.edu/public/jjm2f/rationale.html" onclick="window.open('http://www.iath.virginia.edu/public/jjm2f/rationale.html'); return false">http://www.iath.virginia.edu/public/jjm2f/rationale.html</a>.</div><div class="bibl"><span class="ref" id="mcgann2001"><!-- close -->McGann 2001</span> McGann, J. J. <cite class="title italic">Radiant Textuality: Literature After the World Wide Web</cite>. New York:
                    Palgrave, 2001. </div><div class="bibl"><span class="ref" id="mckenzie1999"><!-- close -->McKenzie 1999</span> McKenzie, D. F. <cite class="title italic">Bibliography and the Sociology of Texts</cite>. Cambridge
                    University Press, 1999.</div><div class="bibl"><span class="ref" id="mustazza2014"><!-- close -->Mustazza 2014</span> Mustazza, C. <a class="ref" href="https://sites.google.com/site/nehhipstas/project-pages/chris-mustazza" onclick="window.open('https://sites.google.com/site/nehhipstas/project-pages/chris-mustazza'); return false">https://sites.google.com/site/nehhipstas/project-pages/chris-mustazza</a>.</div><div class="bibl"><span class="ref" id="nyhan2014"><!-- close -->Nyhan and Flynn 2014</span> Nyhan, J. and Flynn, A. "Oral History, audio-visual materials and Digital Humanities: a
                        new ‘grand challenge’". In AV in DH Workshop Proceedings, Digital
                    Humanities Conference. Lausanne, Switzerland, July 2014. <a class="ref" href="https://avindh2014.wordpress.com/abstracts/#ab4" onclick="window.open('https://avindh2014.wordpress.com/abstracts/#ab4'); return false">https://avindh2014.wordpress.com/abstracts/#ab4</a></div><div class="bibl"><span class="ref" id="otlet1990"><!-- close -->Otlet 1990</span> Otlet, P. <cite class="title italic">International Organisation and Dissemination of Knowledge: Selected Essays
                        of Paul Otlet</cite>. Amsterdam: Elsevier for the International Federation
                    of Documentation, 1990.</div><div class="bibl"><span class="ref" id="provdm"><!-- close -->PROV-DM</span> "PROV-DM: The PROV Data
                        Model", Luc Moreau, Paolo Missier (eds.), W3C Recommendation, 30
                    April 2013,  <a class="ref" href="http://www.w3.org/TR/prov-dm/" onclick="window.open('http://www.w3.org/TR/prov-dm/'); return false">http://www.w3.org/TR/prov-dm/</a> Latest version available. </div><div class="bibl"><span class="ref" id="renear1996"><!-- close -->Renear 1996</span> Renear, A. H., Mylonas, E., and
                    Durand, D. "Refining Our Notion of What Text Really Is: The
                        Problem of Overlapping Hierarchies." In <cite class="title italic">Research
                        in Humanities Computing</cite>, edited by Nancy Ide and Susan Hockey.
                    Oxford University Press, 1996. <a class="ref" href="http://hdl.handle.net/2142/9407" onclick="window.open('http://hdl.handle.net/2142/9407'); return false">http://hdl.handle.net/2142/9407</a>.</div><div class="bibl"><span class="ref" id="renar2004"><!-- close -->Renear 2004</span> Renear, A. H. "Text
                        Encoding." In <cite class="title italic">A Companion to Digital
                        Humanities</cite>, edited by Susan Schreibman, Ray Siemens, and John
                    Unsworth. Blackwell Publishing Ltd, 2004, 218–39. <a class="ref" href="http://onlinelibrary.wiley.com.ezproxy.lib.utexas.edu/doi/10.1002/9780470999875.ch17/summary" onclick="window.open('http://onlinelibrary.wiley.com.ezproxy.lib.utexas.edu/doi/10.1002/9780470999875.ch17/summary'); return false">http://onlinelibrary.wiley.com.ezproxy.lib.utexas.edu/doi/10.1002/9780470999875.ch17/summary</a>.</div><div class="bibl"><span class="ref" id="renear2005"><!-- close -->Renear 2005</span> Renear, A. H. "Text from several different perspectives, the role of context in markup
                        semantics." In <cite class="title italic">Atti della conferenza
                        internazionale CLiP 2003, Computer Literacy and Philology (Firenze, 4–5
                        December 2003)</cite>, edited by C. Nicolas and M. Moneglia. Florence:
                    University of Florence Press, 2005.</div><div class="bibl"><span class="ref" id="renear2007"><!-- close -->Renear and Durbin 2007</span> Renear, A. H. and Durbin,
                    D. "Three of the Four FRBR Group 1 Entity Types are Roles,
                        not Types." In <cite class="title italic">Proceedings of the American
                        Society for Information Science and Technology</cite> 44, no. 1 (2007):
                    1-19. </div><div class="bibl"><span class="ref" id="rettberg2014"><!-- close -->Rettberg 2014</span> Rettberg, E. <a class="ref" href="https://sites.google.com/site/nehhipstas/project-pages/eric-j-rettberg" onclick="window.open('https://sites.google.com/site/nehhipstas/project-pages/eric-j-rettberg'); return false">https://sites.google.com/site/nehhipstas/project-pages/eric-j-rettberg</a>.</div><div class="bibl"><span class="ref" id="rumsey2004"><!-- close -->Rumsey et al. 2004</span> Rumsey, A. S., Allen, D. R.,
                    and Allen, K. Council on Library and Information Resources. <cite class="title italic">Survey of the State of Audio Collections in Academic Libraries</cite>.
                    Washington, D.C.: Council on Library and Information Resources, 2004. <a class="ref" href="http://catalog.hathitrust.org/Record/005405973" onclick="window.open('http://catalog.hathitrust.org/Record/005405973'); return false">http://catalog.hathitrust.org/Record/005405973</a>.</div><div class="bibl"><span class="ref" id="searle1995"><!-- close -->Searle 1995</span> Searle, J. R. <cite class="title italic">The
                        Construction of Social Reality</cite>. New York: The Free Press,
                    1995.</div><div class="bibl"><span class="ref" id="sherwood2006"><!-- close -->Sherwood 2006</span> Sherwood, K. "Elaborate Versionings: Characteristics of Emergent Performance in Three
                        Print/Oral/Aural Poets."
                    <cite class="title italic">Oral Tradition</cite> 21, no. 1 (2006): 119-147.</div><div class="bibl"><span class="ref" id="smith1992"><!-- close -->Smith 1992</span> Smith, M. N. <cite class="title italic">Rowing
                        in Eden: Rereading Emily Dickinson</cite>. Austin: University of Texas
                    Press, 1992.</div><div class="bibl"><span class="ref" id="sperbergmcqueen1990"><!-- close -->Sperberg-McQueen and Burnard 1990</span> Sperberg-McQueen, M. and Burnard, L. eds. <cite class="title italic">Guidelines for
                        the Encoding and Interchange of Machine-readable Texts</cite>. Draft
                    version 1.0. Chicago and Oxford: Association for Computers and the
                    Humanities/Association Computational Linguistics/ Association for Literary and
                    Linguistic Computing, 1990.</div><div class="bibl"><span class="ref" id="sterne2006"><!-- close -->Sterne 2006</span> Sterne, J. "<a class="ref" href="http://sterneworks.org/mp3.pdf" onclick="window.open('http://sterneworks.org/mp3.pdf'); return false">The MP3 as Cultural
                            Artifact</a>." <cite class="title italic">New Media and
                        Society </cite>8, no. 5 (November 2006): 825-842.</div><div class="bibl"><span class="ref" id="sterne2012"><!-- close -->Sterne 2012</span> Sterne, J. "Sonic
                        Imaginations." In Sterne, J. (ed.), <cite class="title italic">The Sound
                        Studies Reader</cite>, edited by Jonathon Sterne. New York: Routledge,
                    2012: 1-18.</div><div class="bibl"><span class="ref" id="svartvik1980"><!-- close -->Svartvik and Quirk 1980</span> Svartvik, J. and Quirk,
                    R. eds. A Corpus of English Conversation. <cite class="title italic">Lund Studies in
                        English</cite> 56. Lund: Lund University Press, 1980.</div><div class="bibl"><span class="ref" id="tei2004"><!-- close -->TEI Consortium 2004</span> TEI Consortium, eds. <cite class="title italic">The XML Version of the TEI Guidelines: Notes for TEI P4
                        Guidelines for Electronic Text Encoding and Interchange</cite>
                    XML-compatible edition. Text Encoding Initiative (June 2004). <a class="ref" href="http://www.tei-c.org/Vault/P5/1.0.1/doc/tei-p4-doc/html/index-notes.html" onclick="window.open('http://www.tei-c.org/Vault/P5/1.0.1/doc/tei-p4-doc/html/index-notes.html'); return false">http://www.tei-c.org/Vault/P5/1.0.1/doc/tei-p4-doc/html/index-notes.html</a>.</div><div class="bibl"><span class="ref" id="tei2014"><!-- close -->TEI Consortium 2014</span> TEI Consortium, eds. <cite class="title italic">TEI P5: Guidelines for Electronic Text Encoding and
                        Interchange</cite>. Version 2.6.0. TEI Consortium (2014). <a class="ref" href="http://www.tei-c.org/Guidelines/P5/" onclick="window.open('http://www.tei-c.org/Guidelines/P5/'); return false">http://www.tei-c.org/Guidelines/P5/</a>.</div><div class="bibl"><span class="ref" id="tedlock1983"><!-- close -->Tedlock 1983</span> Tedlock, D. <cite class="title italic">The
                        Spoken Word and the Work of Interpretation</cite>. University of
                    Pennsylvania Publications in Conduct and Communication. Philadelphia: University
                    of Pennsylvania Press, 1983.</div><div class="bibl"><span class="ref" id="loc2012"><!-- close -->The Library of Congress 2012</span> The Library of Congress.
                        "Bibliographic Framework as a Web of Data: Linked Data
                        Model and Supporting Services." Washington, DC: The Library of
                    Congress, 2012.</div><div class="bibl"><span class="ref" id="tillet2004"><!-- close -->Tillet 2004</span> Tillet, Barbara "FRBR: A Conceptual Model for the Bibliographic Universe." Library of
                    Congress Cataloging Distribution Service, 2004.</div><div class="bibl"><span class="ref" id="vanmalssen2014"><!-- close -->Van Malssen 2014</span> Van Malssen, K. "BIBFRAME AV Modeling Study: Defining a Flexible Model for
                        Description of Audiovisual Resources." Library of Congress (May 15,
                    2014). <a class="ref" href="http://www.loc.gov/bibframe/" onclick="window.open('http://www.loc.gov/bibframe/'); return false">http://www.loc.gov/bibframe/</a>.</div><div class="bibl"><span class="ref" id="witmore2010"><!-- close -->Witmore 2010</span> Witmore, M. "Text: A Massively Addressable Object."
                    <cite class="title italic">Wine Dark Sea</cite> (December 31, 2010). <a class="ref" href="http://winedarksea.org/?p=926" onclick="window.open('http://winedarksea.org/?p=926'); return false">http://winedarksea.org/?p=926</a>.</div></div><div class="toolbar"><a href="/dhq/vol/10/3/index.html">2016 10.3</a>
             | 
            <a rel="external" href="/dhq/vol/10/3/000254.xml">XML</a>
            | 
            <a href="#" onclick="javascript:window.print();" title="Click for print friendly version">Print Article</a></div></div><script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dhquarterly'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script><div id="comments"><div id="disqus_thread"/><script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dhquarterly'; // required: replace example with your forum shortname

    // The following are highly recommended additional parameters. Remove the slashes in front to use.
    var disqus_identifier = '000254';
    var disqus_url = 'http://www.digitalhumanities.org/dhq/vol/10/3/000254/000254.html';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><div id="footer"> 
            URL: http://www.digitalhumanities.org/dhq/vol/10/3/000254/000254.html<br/>Last updated:
            <script type="text/javascript">
                var monthArray = new initArray("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December");
                var lastModifiedDate = new Date(document.lastModified);
                var currentDate = new Date();
                document.write(" ",monthArray[(lastModifiedDate.getMonth()+1)]," ");
                document.write(lastModifiedDate.getDate(),", ",(lastModifiedDate.getFullYear()));
            </script><br/> Comments: <a href="mailto:dhqinfo@digitalhumanities.org" class="footer">dhqinfo@digitalhumanities.org</a><br/> Published by:
            <a href="http://www.digitalhumanities.org" class="footer">The Alliance of Digital Humanities Organizations</a><br/>Affiliated with: <a href="http://llc.oxfordjournals.org/">Literary and Linguistic Computing</a><br/> Copyright 2005 - <script type="text/javascript">
                document.write(currentDate.getFullYear());</script><br/><a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nd/4.0/88x31.png"/></a><br/>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nd/4.0/">Creative Commons Attribution-NoDerivatives 4.0 International License</a>.
        </div></div></div></body></html>